{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of AdaTempScal on ResNet50 for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.extend(['..'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from mixNmatch_cal import temperature_scaling\n",
    "from scipy_models import LTS, HTS, HistTS, TS, HnLTS, BTS\n",
    "from models import AdaTS, DNNbasedT\n",
    "%aimport utils\n",
    "from utils import compare_results, calib_split, get_CIFAR10_C, NumpyDataset, load_model, predict_logits, compute_metrics, onehot_encode, softmax\n",
    "%aimport adats_utils\n",
    "from adats_utils import fitAdaTS, fitCV_AdaTS, fitHistTS\n",
    "%aimport mixNmatch_cal\n",
    "from mixNmatch_cal import ets_calibrate, mir_calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath} \\usepackage{amssymb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and precomputed logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_PATH = '../../data/CIFAR10'\n",
    "CIFAR10C_PATH = '../../data/CIFAR-10-C'\n",
    "MODEL_PATH = '../../trained_models/CIFAR10/resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(CIFAR10_PATH, 'train_imas.npy'))\n",
    "y_train = np.load(os.path.join(CIFAR10_PATH, 'train_labels.npy'))\n",
    "\n",
    "X_val = np.load(os.path.join(CIFAR10_PATH, 'val_imas.npy'))\n",
    "y_val = np.load(os.path.join(CIFAR10_PATH, 'val_labels.npy'))\n",
    "\n",
    "X_test = np.load(os.path.join(CIFAR10_PATH, 'test_imas.npy'))\n",
    "y_test = np.load(os.path.join(CIFAR10_PATH, 'test_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = np.load(os.path.join(MODEL_PATH, 'train_logits.npy'))\n",
    "Z_val = np.load(os.path.join(MODEL_PATH, 'val_logits.npy'))\n",
    "Z_test = np.load(os.path.join(MODEL_PATH, 'test_logits.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2171.642972\n",
      "         Iterations: 7\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n"
     ]
    }
   ],
   "source": [
    "N, dim = Z_train.shape\n",
    "\n",
    "### Temp-Scal as baseline:\n",
    "tempScaler = TS(dim)\n",
    "tempScaler.fit(Z_val, y_val, v=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hts = HTS(dim)\n",
    "hts.fit(Z_val, y_val, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts = LTS(dim)\n",
    "lts.fit(Z_val, y_val, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlts = HnLTS(dim)\n",
    "hlts.fit(Z_val, y_val, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted bin 0, with T: 2.79\r",
      "Fitted bin 1, with T: 2.76\r",
      "Fitted bin 2, with T: 3.23\r",
      "Fitted bin 3, with T: 3.34\r",
      "Fitted bin 4, with T: 2.93\r",
      "Fitted bin 5, with T: 2.51\r",
      "Fitted bin 6, with T: 2.06\r",
      "Fitted bin 7, with T: 3.21\r",
      "Fitted bin 8, with T: 2.46\r",
      "Fitted bin 9, with T: 2.09\r",
      "Fitted bin 10, with T: 2.87\r",
      "Fitted bin 11, with T: 3.00\r",
      "Fitted bin 12, with T: 2.83\r",
      "Fitted bin 13, with T: 2.73\r",
      "Fitted bin 14, with T: 3.01\r",
      "Fitted bin 15, with T: 3.80\r",
      "Fitted bin 16, with T: 2.58\r",
      "Fitted bin 17, with T: 2.27\r",
      "Fitted bin 18, with T: 2.91\r",
      "Fitted bin 19, with T: 2.65\r",
      "Fitted bin 20, with T: 2.35\r",
      "Fitted bin 21, with T: 3.19\r",
      "Fitted bin 22, with T: 3.75\r",
      "Fitted bin 23, with T: 3.15\r",
      "Fitted bin 24, with T: 2.63\r",
      "Fitted bin 25, with T: 3.76\r",
      "Fitted bin 26, with T: 2.62\r",
      "Fitted bin 27, with T: 2.91\r",
      "Fitted bin 28, with T: 3.11\r",
      "Fitted bin 29, with T: 2.53\r",
      "Fitted bin 30, with T: 2.98\r",
      "Fitted bin 31, with T: 2.82\r",
      "Fitted bin 32, with T: 2.82\r",
      "Fitted bin 33, with T: 3.29\r",
      "Fitted bin 34, with T: 2.49\r",
      "Fitted bin 35, with T: 3.16\r",
      "Fitted bin 36, with T: 2.68\r",
      "Fitted bin 37, with T: 2.37\r",
      "Fitted bin 38, with T: 2.91\r",
      "Fitted bin 39, with T: 3.42\r",
      "Fitted bin 40, with T: 2.47\r",
      "Fitted bin 41, with T: 2.72\r",
      "Fitted bin 42, with T: 2.90\r",
      "Fitted bin 43, with T: 3.72\r",
      "Fitted bin 44, with T: 3.24\r",
      "Fitted bin 45, with T: 2.59\r",
      "Fitted bin 46, with T: 2.72\r",
      "Fitted bin 47, with T: 2.11\r",
      "Fitted bin 48, with T: 2.93\r",
      "Fitted bin 49, with T: 2.40\r"
     ]
    }
   ],
   "source": [
    "bts = BTS()\n",
    "bts.fit(Z_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 174, NLL: 2.974e+03, at time: 5.65s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dfe4f0cf6004>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mPTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaTS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDNNbasedT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mPTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitAdaTS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\repos\\adaptive-tempscaling\\code\\adats_utils.py\u001b[0m in \u001b[0;36mfitAdaTS\u001b[1;34m(adaTS, X, Y, epochs, batch_size, lr, optimizer, weight_decay, v, target_file, dev)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m# Train step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0m_nll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\calibration\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\calibration\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PTS = AdaTS(DNNbasedT(dim, hs=[5, 5]))\n",
    "PTS = fitAdaTS(PTS, Z_val, y_val, epochs=30000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisTS = HistTS()\n",
    "hisTS.fit(Z_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on train set:\n",
      "Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal             99.94%         0.12%        47.21%    1.104e-03     2.701e-03\n",
      "TempScal          99.94%         5.36%        71.37%    8.604e-03     5.812e-02\n",
      "BTS               99.94%         4.75%        72.62%    1.003e-02     5.309e-02\n",
      "ETS               99.94%         7.37%        72.93%    1.287e-02     8.031e-02\n",
      "MIR               99.94%         4.70%        78.25%    1.078e-02     5.266e-02\n",
      "HTS               99.94%         4.79%        74.31%    9.582e-03     5.312e-02\n",
      "LTS               99.94%         5.32%        72.07%    9.458e-03     5.824e-02\n",
      "HnLTS             99.94%         4.79%        74.61%    1.012e-02     5.339e-02\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on train set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_train, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_train),\n",
    "                             'BTS': bts.predictive(Z_train),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_train, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_train),\n",
    "                             'HTS': hts.predictive(Z_train),\n",
    "                             'LTS': lts.predictive(Z_train),\n",
    "                             'HnLTS': hlts.predictive(Z_train)}, target=y_train, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on val set:\n",
      "Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal             86.72%        10.31%        73.80%    2.300e-01     7.737e-01\n",
      "TempScal          86.72%         3.06%        79.67%    1.967e-01     4.343e-01\n",
      "BTS               86.72%         2.20%        80.17%    1.938e-01     4.275e-01\n",
      "ETS               86.72%         3.40%        80.22%    1.958e-01     4.382e-01\n",
      "MIR               86.72%         1.67%        82.23%    1.935e-01     4.188e-01\n",
      "HTS               86.72%         2.16%        80.79%    1.953e-01     4.305e-01\n",
      "LTS               86.72%         2.84%        78.86%    1.947e-01     4.278e-01\n",
      "HnLTS             86.72%         2.07%        79.96%    1.937e-01     4.248e-01\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on val set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_val, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_val),\n",
    "                             'BTS': bts.predictive(Z_val),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_val, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_val),\n",
    "                             'HTS': hts.predictive(Z_val),\n",
    "                             'LTS': lts.predictive(Z_val),\n",
    "                             'HnLTS': hlts.predictive(Z_val)}, target=y_val, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on test set:\n",
      "Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal             86.13%        10.71%        49.03%    2.392e-01     7.897e-01\n",
      "TempScal          86.13%         2.54%        51.53%    2.037e-01     4.473e-01\n",
      "BTS               86.13%         1.86%        60.38%    2.036e-01     4.498e-01\n",
      "ETS               86.13%         2.84%        43.68%    2.029e-01     4.515e-01\n",
      "MIR               86.13%         1.33%        80.74%    2.023e-01     4.435e-01\n",
      "HTS               86.13%         1.45%        45.17%    2.024e-01     4.448e-01\n",
      "LTS               86.13%         2.41%        43.20%    2.019e-01     4.399e-01\n",
      "HnLTS             86.13%         1.58%        45.22%    2.011e-01     4.386e-01\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on test set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_test, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_test),\n",
    "                             'BTS': bts.predictive(Z_test),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_test, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_test),\n",
    "                             'HTS': hts.predictive(Z_test),\n",
    "                             'LTS': lts.predictive(Z_test),\n",
    "                             'HnLTS': hlts.predictive(Z_test)}, target=y_test, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54bfb3641487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlhaTempScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(25, 25))\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_train)\n",
    "ax[0, 0].hist(Ts, bins=50)\n",
    "ax[0, 0].set_xlabel('T', fontsize=22)\n",
    "ax[0, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_val)\n",
    "ax[0, 1].hist(Ts, bins=50)\n",
    "ax[0, 1].set_xlabel('T', fontsize=22)\n",
    "ax[0, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_test)\n",
    "ax[0, 2].hist(Ts, bins=50)\n",
    "ax[0, 2].set_xlabel('T', fontsize=22)\n",
    "ax[0, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_train)\n",
    "ax[1, 0].hist(Ts, bins=50)\n",
    "ax[1, 0].set_xlabel('T', fontsize=22)\n",
    "ax[1, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_val)\n",
    "ax[1, 1].hist(Ts, bins=50)\n",
    "ax[1, 1].set_xlabel('T', fontsize=22)\n",
    "ax[1, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_test)\n",
    "ax[1, 2].hist(Ts, bins=50)\n",
    "ax[1, 2].set_xlabel('T', fontsize=22)\n",
    "ax[1, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_train)\n",
    "ax[2, 0].hist(Ts, bins=50)\n",
    "ax[2, 0].set_xlabel('T', fontsize=22)\n",
    "ax[2, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_val)\n",
    "ax[2, 1].hist(Ts, bins=50)\n",
    "ax[2, 1].set_xlabel('T', fontsize=22)\n",
    "ax[2, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_test)\n",
    "ax[2, 2].hist(Ts, bins=50)\n",
    "ax[2, 2].set_xlabel('T', fontsize=22)\n",
    "ax[2, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected temperature for different confidences in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc, lc, hi, li = calib_split(Z_test, y_test)\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[hc | hi], y_test[hc | hi]);\n",
    "T_hc = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[lc | li], y_test[lc | li]);\n",
    "T_lc = ts_aux.T.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TslH = lhaTempScaler.get_T(Z_test)\n",
    "TsDNN = dnnaTempScaler.get_T(Z_test)\n",
    "TsBDNN = bdnnaTempScaler.get_T(Z_test)\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(23, 25))\n",
    "\n",
    "\n",
    "ax[0, 0].hist(TslH[hc | hi])\n",
    "ax[0, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[0, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[hc | hi])), fontsize=26)\n",
    "ax[0, 0].legend(fontsize=18)\n",
    "\n",
    "ax[0, 1].hist(TslH[lc | li])\n",
    "ax[0, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[0, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[lc | li])), fontsize=26)\n",
    "ax[0, 1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[1, 0].hist(TsDNN[hc | hi])\n",
    "ax[1, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[1, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[hc | hi])), fontsize=26)\n",
    "ax[1, 0].legend(fontsize=18)\n",
    "\n",
    "ax[1, 1].hist(TsDNN[lc | li])\n",
    "ax[1, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[1, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[lc | li])), fontsize=26)\n",
    "ax[1, 1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[2, 0].hist(TsBDNN[hc | hi])\n",
    "ax[2, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[2, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[hc | hi])), fontsize=26)\n",
    "ax[2, 0].legend(fontsize=18)\n",
    "\n",
    "ax[2, 1].hist(TsBDNN[lc | li])\n",
    "ax[2, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[2, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[lc | li])), fontsize=26)\n",
    "ax[2, 1].legend(fontsize=18)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.yaxis.set_tick_params(labelleft=True)\n",
    "    _ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    _ax.set_xlabel('T', fontsize=22)\n",
    "    _ax.set_ylabel('Count', fontsize=22)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = softmax(Z_test, axis=1)\n",
    "test_confs = np.max(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 8))\n",
    "\n",
    "ax.hist(test_confs, bins=200)\n",
    "\n",
    "ax.set_xlabel('Confidence', fontsize=22)\n",
    "ax.set_ylabel('Count', fontsize=22)\n",
    "ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.argsort(test_confs)\n",
    "\n",
    "q1, q2, q3, q4 = ix[:len(test_confs)//4], ix[len(test_confs)//4:len(test_confs)//2], ix[len(test_confs)//2: 3*len(test_confs)//4], ix[3*len(test_confs)//4:]\n",
    "\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q1], y_test[q1]);\n",
    "T_q1 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q2], y_test[q2]);\n",
    "T_q2 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q3], y_test[q3]);\n",
    "T_q3 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q4], y_test[q4]);\n",
    "T_q4 = ts_aux.T.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "TslH = lhaTempScaler.get_T(Z_test)\n",
    "TsDNN = dnnaTempScaler.get_T(Z_test)\n",
    "TsBDNN = bdnnaTempScaler.get_T(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, sharex=True, sharey=True, figsize=(30, 25))\n",
    "\n",
    "\n",
    "ax[0, 0].hist(TslH[q1])\n",
    "ax[0, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[0, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q1])), fontsize=26)\n",
    "\n",
    "ax[0, 1].hist(TslH[q2])\n",
    "ax[0, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[0, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q2])), fontsize=26)\n",
    "\n",
    "ax[0, 2].hist(TslH[q3])\n",
    "ax[0, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[0, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q3])), fontsize=26)\n",
    "\n",
    "ax[0, 3].hist(TslH[q4])\n",
    "ax[0, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[0, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "ax[1, 0].hist(TsDNN[q1])\n",
    "ax[1, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[1, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q1])), fontsize=26)\n",
    "\n",
    "ax[1, 1].hist(TsDNN[q2])\n",
    "ax[1, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[1, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q2])), fontsize=26)\n",
    "\n",
    "ax[1, 2].hist(TsDNN[q3])\n",
    "ax[1, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[1, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q3])), fontsize=26)\n",
    "\n",
    "ax[1, 3].hist(TsDNN[q4])\n",
    "ax[1, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[1, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "ax[2, 0].hist(TsBDNN[q1])\n",
    "ax[2, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[2, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q1])), fontsize=26)\n",
    "\n",
    "ax[2, 1].hist(TsBDNN[q2])\n",
    "ax[2, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[2, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q2])), fontsize=26)\n",
    "\n",
    "ax[2, 2].hist(TsBDNN[q3])\n",
    "ax[2, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[2, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q3])), fontsize=26)\n",
    "\n",
    "ax[2, 3].hist(TsBDNN[q4])\n",
    "ax[2, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[2, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.yaxis.set_tick_params(labelleft=True)\n",
    "    _ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.set_xlabel('T', fontsize=22)\n",
    "    _ax.set_ylabel('Count', fontsize=22)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corruption Robustness: CIFAR10-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c = get_CIFAR10_C(CIFAR10C_PATH)\n",
    "\n",
    "categories = list(cifar10c.keys())\n",
    "categories.remove('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_transforms_test=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = load_model('resnet50', 'cifar10', model_path='../../trained_models') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness without exposure to corrupted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_logits = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_logits[category] = {}\n",
    "    print('Computing predictions for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        test_data = NumpyDataset(cifar10c[category][severity], cifar10c['labels'][:10000], transform=cifar10_transforms_test)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=256)\n",
    "        cifar10c_logits[category][severity] = predict_logits(net, test_dataloader, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_metrics_uncal = {}\n",
    "cifar10c_metrics_tscal = {}\n",
    "cifar10c_metrics_lhtscal = {}\n",
    "cifar10c_metrics_dnntscal = {}\n",
    "cifar10c_metrics_bdnntscal = {}\n",
    "cifar10c_metrics_histtscal = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_metrics_uncal[category] = {}\n",
    "    cifar10c_metrics_tscal[category] = {}\n",
    "    cifar10c_metrics_lhtscal[category] = {}\n",
    "    cifar10c_metrics_dnntscal[category] = {}\n",
    "    cifar10c_metrics_bdnntscal[category] = {}\n",
    "    cifar10c_metrics_histtscal[category] = {}\n",
    "    print('Computing metrics for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_metrics_uncal[category][severity] = compute_metrics(cifar10c_logits[category][severity], cifar10c['labels'][:10000])\n",
    "        cifar10c_metrics_tscal[category][severity] = compute_metrics(tempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_lhtscal[category][severity] = compute_metrics(lhaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_dnntscal[category][severity] = compute_metrics(dnnaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_bdnntscal[category][severity] = compute_metrics(bdnnaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_histtscal[category][severity] = compute_metrics(hisTS.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sev_uncal = np.zeros((5, 4))\n",
    "mean_sev_tscal = np.zeros((5, 4))\n",
    "mean_sev_lhtscal = np.zeros((5, 4))\n",
    "mean_sev_dnntscal = np.zeros((5, 4))\n",
    "mean_sev_bdnntscal = np.zeros((5, 4))\n",
    "mean_sev_histtscal = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_sev_uncal[i] += cifar10c_metrics_uncal[cat][i+1]\n",
    "        mean_sev_tscal[i] += cifar10c_metrics_tscal[cat][i+1]\n",
    "        mean_sev_lhtscal[i] += cifar10c_metrics_lhtscal[cat][i+1]\n",
    "        mean_sev_dnntscal[i] += cifar10c_metrics_dnntscal[cat][i+1]\n",
    "        mean_sev_bdnntscal[i] += cifar10c_metrics_bdnntscal[cat][i+1]\n",
    "        mean_sev_histtscal[i] += cifar10c_metrics_histtscal[cat][i+1]\n",
    "        \n",
    "mean_sev_uncal /= len(categories)\n",
    "mean_sev_tscal /= len(categories)\n",
    "mean_sev_lhtscal /= len(categories)\n",
    "mean_sev_dnntscal /= len(categories)\n",
    "mean_sev_bdnntscal /= len(categories)\n",
    "mean_sev_histtscal /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(28, 33))\n",
    "\n",
    "# ax[0].plot(mean_sev_uncal[:, 1], ls='--', marker='*', label='Uncalibrated')\n",
    "ax[0].plot(mean_sev_tscal[:, 1], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[0].plot(mean_sev_lhtscal[:, 1], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[0].plot(mean_sev_dnntscal[:, 1], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_bdnntscal[:, 1], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_histtscal[:, 1], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[0].set_ylabel('ECE', fontsize=22)\n",
    "\n",
    "# ax[1].plot(mnll_sev_uncal, label='Uncalibrated')\n",
    "ax[1].plot(mean_sev_tscal[:, 3], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[1].plot(mean_sev_lhtscal[:, 3], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[1].plot(mean_sev_dnntscal[:, 3], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_bdnntscal[:, 3], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_histtscal[:, 3], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[1].set_ylabel('NLL', fontsize=22)\n",
    "\n",
    "ax[2].plot(mean_sev_tscal[:, 2], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[2].plot(mean_sev_lhtscal[:, 2], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[2].plot(mean_sev_dnntscal[:, 2], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_bdnntscal[:, 2], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_histtscal[:, 2], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[2].set_ylabel('Brier Score', fontsize=22)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.set_xticks(np.arange(5))\n",
    "    _ax.set_xticklabels(np.arange(5) + 1)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    _ax.set_xlabel('Corruption level', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_TslH= {}\n",
    "cifar10c_TsDNN= {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_TslH[category] = {}\n",
    "    cifar10c_TsDNN[category] = {}\n",
    "    print('Computing Ts for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_TslH[category][severity] = lhaTempScaler.get_T(cifar10c_logits[category][severity])\n",
    "        cifar10c_TsDNN[category][severity] = dnnaTempScaler.get_T(cifar10c_logits[category][severity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_TslH = np.zeros(5)\n",
    "mean_TsDNN = np.zeros(5)\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_TslH[i] += np.mean(cifar10c_TslH[cat][i+1])\n",
    "        mean_TsDNN[i] += np.mean(cifar10c_TsDNN[cat][i+1])\n",
    "        \n",
    "mean_TslH /= len(categories)\n",
    "mean_TsDNN /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_TslH)\n",
    "print(mean_TsDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exposure to corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = np.random.permutation(10000)\n",
    "idx_train = rnd_idx[:3000]\n",
    "idx_test = rnd_idx[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.vstack([cifar10c_logits[cat][i+1][idx_train] for cat in categories for i in range(5)])\n",
    "y_train = np.hstack([cifar10c['labels'][idx_train] for cat in categories for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temp-Scal as baseline:\n",
    "tempScaler = TempScaling()\n",
    "tempScaler.fit(train_set, y_train, v=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhaTempScaler = AdaTS(HlogbasedT(dim))\n",
    "lhaTempScaler = fitAdaTS(lhaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnaTempScaler = AdaTS(DNNbasedT(dim))\n",
    "dnnaTempScaler = fitAdaTS(dnnaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdnnaTempScaler = AdaTS(DNNbasedT(dim, hs=[2*dim, 2*dim]))\n",
    "bdnnaTempScaler = fitAdaTS(bdnnaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisTS = HistTS()\n",
    "hisTS.fit(train_set, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_metrics_uncal = {}\n",
    "cifar10c_metrics_tscal = {}\n",
    "cifar10c_metrics_lhtscal = {}\n",
    "cifar10c_metrics_dnntscal = {}\n",
    "cifar10c_metrics_bdnntscal = {}\n",
    "cifar10c_metrics_histtscal = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_metrics_uncal[category] = {}\n",
    "    cifar10c_metrics_tscal[category] = {}\n",
    "    cifar10c_metrics_lhtscal[category] = {}\n",
    "    cifar10c_metrics_dnntscal[category] = {}\n",
    "    cifar10c_metrics_bdnntscal[category] = {}\n",
    "    cifar10c_metrics_histtscal[category] = {}\n",
    "    print('Computing metrics for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_metrics_uncal[category][severity] = compute_metrics(cifar10c_logits[category][severity][idx_test], cifar10c['labels'][idx_test])\n",
    "        cifar10c_metrics_tscal[category][severity] = compute_metrics(tempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_lhtscal[category][severity] = compute_metrics(lhaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_dnntscal[category][severity] = compute_metrics(dnnaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_bdnntscal[category][severity] = compute_metrics(bdnnaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_histtscal[category][severity] = compute_metrics(hisTS.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sev_uncal = np.zeros((5, 4))\n",
    "mean_sev_tscal = np.zeros((5, 4))\n",
    "mean_sev_lhtscal = np.zeros((5, 4))\n",
    "mean_sev_dnntscal = np.zeros((5, 4))\n",
    "mean_sev_bdnntscal = np.zeros((5, 4))\n",
    "mean_sev_histtscal = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_sev_uncal[i] += cifar10c_metrics_uncal[cat][i+1]\n",
    "        mean_sev_tscal[i] += cifar10c_metrics_tscal[cat][i+1]\n",
    "        mean_sev_lhtscal[i] += cifar10c_metrics_lhtscal[cat][i+1]\n",
    "        mean_sev_dnntscal[i] += cifar10c_metrics_dnntscal[cat][i+1]\n",
    "        mean_sev_bdnntscal[i] += cifar10c_metrics_bdnntscal[cat][i+1]\n",
    "        mean_sev_histtscal[i] += cifar10c_metrics_histtscal[cat][i+1]\n",
    "        \n",
    "mean_sev_uncal /= len(categories)\n",
    "mean_sev_tscal /= len(categories)\n",
    "mean_sev_lhtscal /= len(categories)\n",
    "mean_sev_dnntscal /= len(categories)\n",
    "mean_sev_bdnntscal /= len(categories)\n",
    "mean_sev_histtscal /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(28, 33))\n",
    "\n",
    "# ax[0].plot(mean_sev_uncal[:, 1], ls='--', marker='*', label='Uncalibrated')\n",
    "ax[0].plot(mean_sev_tscal[:, 1], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[0].plot(mean_sev_lhtscal[:, 1], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[0].plot(mean_sev_dnntscal[:, 1], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_bdnntscal[:, 1], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_histtscal[:, 1], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[0].set_ylabel('ECE', fontsize=22)\n",
    "\n",
    "# ax[1].plot(mnll_sev_uncal, label='Uncalibrated')\n",
    "ax[1].plot(mean_sev_tscal[:, 3], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[1].plot(mean_sev_lhtscal[:, 3], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[1].plot(mean_sev_dnntscal[:, 3], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_bdnntscal[:, 3], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_histtscal[:, 3], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[1].set_ylabel('NLL', fontsize=22)\n",
    "\n",
    "ax[2].plot(mean_sev_tscal[:, 2], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[2].plot(mean_sev_lhtscal[:, 2], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[2].plot(mean_sev_dnntscal[:, 2], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_bdnntscal[:, 2], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_histtscal[:, 2], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[2].set_ylabel('Brier Score', fontsize=22)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.set_xticks(np.arange(5))\n",
    "    _ax.set_xticklabels(np.arange(5) + 1)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    _ax.set_xlabel('Corruption level', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
