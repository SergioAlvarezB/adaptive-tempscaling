{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caafb26b",
   "metadata": {},
   "source": [
    "# Analysis of AdaTempScal on ResNet50 for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62306f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4377683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "829c55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.extend(['..'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from models import AdaTS, TempScaling, HlogbasedT, DNNbasedT, HistTS, EnsembleTS\n",
    "%aimport utils\n",
    "from utils import compare_results, calib_split, get_CIFAR10_C, NumpyDataset, load_model, predict_logits, compute_metrics, onehot_encode\n",
    "%aimport adats_utils\n",
    "from adats_utils import fitAdaTS, fitCV_AdaTS, fitHistTS\n",
    "%aimport mixNmatch_cal\n",
    "from mixNmatch_cal import ets_calibrate, mir_calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f43d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2d5000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath} \\usepackage{amssymb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a8f9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75788072",
   "metadata": {},
   "source": [
    "## Load data and precomputed logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "937402b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_PATH = '../../data/CIFAR10'\n",
    "CIFAR10C_PATH = '../../data/CIFAR-10-C'\n",
    "MODEL_PATH = '../../trained_models/CIFAR10/resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4340c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(CIFAR10_PATH, 'train_imas.npy'))\n",
    "y_train = np.load(os.path.join(CIFAR10_PATH, 'train_labels.npy'))\n",
    "\n",
    "X_val = np.load(os.path.join(CIFAR10_PATH, 'val_imas.npy'))\n",
    "y_val = np.load(os.path.join(CIFAR10_PATH, 'val_labels.npy'))\n",
    "\n",
    "X_test = np.load(os.path.join(CIFAR10_PATH, 'test_imas.npy'))\n",
    "y_test = np.load(os.path.join(CIFAR10_PATH, 'test_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fddb67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = np.load(os.path.join(MODEL_PATH, 'train_logits.npy'))\n",
    "Z_val = np.load(os.path.join(MODEL_PATH, 'val_logits.npy'))\n",
    "Z_test = np.load(os.path.join(MODEL_PATH, 'test_logits.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef73b9",
   "metadata": {},
   "source": [
    "### Calibrate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74739fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_rand = np.random.permutation(X_val.shape[0])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ba4d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 784, NLL: 4.299e+02, Temp: 2.581, at time: 0.35s\r"
     ]
    }
   ],
   "source": [
    "N, dim = Z_train.shape\n",
    "\n",
    "### Temp-Scal as baseline:\n",
    "tempScaler = TempScaling()\n",
    "tempScaler.fit(Z_val[ix_rand], y_val[ix_rand], v=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f51e06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 9994, NLL: 5.003e+02, at time: 14.23s\r"
     ]
    }
   ],
   "source": [
    "lhaTempScaler = AdaTS(HlogbasedT(dim))\n",
    "lhaTempScaler = fitAdaTS(lhaTempScaler, Z_val[ix_rand], y_val[ix_rand], epochs=10000, batch_size=1000, lr=1e-4, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb963c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 29994, NLL: 4.101e+02, at time: 40.05s\r"
     ]
    }
   ],
   "source": [
    "dnnaTempScaler = AdaTS(DNNbasedT(dim))\n",
    "dnnaTempScaler = fitAdaTS(dnnaTempScaler, Z_val[ix_rand], y_val[ix_rand], epochs=30000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ef15145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 29994, NLL: 4.086e+02, at time: 48.31s\r"
     ]
    }
   ],
   "source": [
    "PTS = AdaTS(DNNbasedT(dim, hs=[5, 5]))\n",
    "PTS = fitAdaTS(PTS, Z_val[ix_rand], y_val[ix_rand], epochs=30000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96214f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hisTS = HistTS()\n",
    "hisTS.fit(Z_val[ix_rand], y_val[ix_rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63d2b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on train set:\n",
      "     Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal                   99.94%         0.11%        45.80%    1.104e-03     2.701e-03\n",
      "TempScal                99.94%         5.40%        65.28%    8.687e-03     5.858e-02\n",
      "ETS                     99.94%         7.43%        43.91%    1.300e-02     8.096e-02\n",
      "MIR                     99.93%         5.19%        57.97%    1.294e-02     5.899e-02\n",
      "logH-TempScal           99.94%         5.51%        35.74%    5.226e-03     5.824e-02\n",
      "DNN-TempScal            99.94%         4.90%        69.01%    1.031e-02     5.482e-02\n",
      "PTS                     99.94%         5.23%        70.69%    1.041e-02     5.795e-02\n",
      "HistH-TempScal          99.94%         4.82%        73.47%    1.114e-02     5.430e-02\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on train set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_train, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_train),\n",
    "                             'ETS': ets_calibrate(Z_val[ix_rand], onehot_encode(y_val[ix_rand]), Z_train, dim),\n",
    "                             'MIR': mir_calibrate(Z_val[ix_rand], onehot_encode(y_val[ix_rand]), Z_train),\n",
    "                             'logH-TempScal': lhaTempScaler.predictive(Z_train),\n",
    "                             'DNN-TempScal': dnnaTempScaler.predictive(Z_train),\n",
    "                             'PTS': PTS.predictive(Z_train),\n",
    "                             'HistH-TempScal': hisTS.predictive(Z_train)}, target=y_train, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "923ee15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on validation set:\n",
      "     Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal                   86.72%        10.30%        73.80%    2.300e-01     7.737e-01\n",
      "TempScal                86.72%         2.45%        55.53%    1.967e-01     4.343e-01\n",
      "ETS                     86.72%         2.81%        80.23%    1.958e-01     4.384e-01\n",
      "MIR                     86.84%         0.73%        40.96%    1.966e-01     4.271e-01\n",
      "logH-TempScal           86.72%         5.77%        75.25%    2.125e-01     5.007e-01\n",
      "DNN-TempScal            86.72%         2.32%         8.67%    1.991e-01     4.545e-01\n",
      "PTS                     86.72%         2.11%        15.44%    1.974e-01     4.450e-01\n",
      "HistH-TempScal          86.72%         1.23%         7.75%    1.952e-01     4.420e-01\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on validation set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_val, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_val),\n",
    "                             'ETS': ets_calibrate(Z_val[ix_rand], onehot_encode(y_val[ix_rand]), Z_val, dim),\n",
    "                             'MIR': mir_calibrate(Z_val[ix_rand], onehot_encode(y_val[ix_rand]), Z_val),\n",
    "                             'logH-TempScal': lhaTempScaler.predictive(Z_val),\n",
    "                             'DNN-TempScal': dnnaTempScaler.predictive(Z_val),\n",
    "                             'PTS': PTS.predictive(Z_val),\n",
    "                             'HistH-TempScal': hisTS.predictive(Z_val)}, target=y_val, M=15, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c31202f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on test set:\n",
      "     Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal                   86.13%        10.69%        35.80%    2.392e-01     7.897e-01\n",
      "TempScal                86.13%         2.36%        16.96%    2.036e-01     4.473e-01\n",
      "ETS                     86.13%         2.33%        16.63%    2.029e-01     4.517e-01\n",
      "MIR                     86.15%         0.93%        41.82%    2.053e-01     4.472e-01\n",
      "logH-TempScal           86.13%         6.12%        28.29%    2.202e-01     5.101e-01\n",
      "DNN-TempScal            86.13%         2.59%        20.53%    2.074e-01     4.751e-01\n",
      "PTS                     86.13%         1.96%        25.04%    2.049e-01     4.537e-01\n",
      "HistH-TempScal          86.13%         1.01%        25.77%    2.022e-01     4.542e-01\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on test set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_test, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_test),\n",
    "                             'ETS': ets_calibrate(Z_val[ix_rand], onehot_encode(y_val[ix_rand]), Z_test, dim),\n",
    "                             'MIR': mir_calibrate(Z_val[ix_rand], onehot_encode(y_val[ix_rand]), Z_test),\n",
    "                             'logH-TempScal': lhaTempScaler.predictive(Z_test),\n",
    "                             'DNN-TempScal': dnnaTempScaler.predictive(Z_test),\n",
    "                             'PTS': PTS.predictive(Z_test),\n",
    "                             'HistH-TempScal': hisTS.predictive(Z_test)}, target=y_test, M=15, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c86a3955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2555027e-04, 4.2628191e-04, 3.3185841e-03, ..., 3.4811085e-03,\n",
       "        4.0681465e-04, 4.0351352e-04],\n",
       "       [5.0656661e-02, 5.0656661e-02, 3.5964174e-03, ..., 8.8662712e-04,\n",
       "        8.5000002e-01, 2.7230300e-03],\n",
       "       [1.1013215e-02, 1.1656707e-03, 4.4779759e-04, ..., 4.3475130e-04,\n",
       "        9.7146118e-01, 5.7745418e-03],\n",
       "       ...,\n",
       "       [4.6953425e-04, 4.8792403e-04, 5.5009578e-03, ..., 1.0800964e-03,\n",
       "        7.6941797e-04, 6.0167187e-04],\n",
       "       [5.4716974e-01, 2.1985815e-01, 3.2588456e-02, ..., 2.3394532e-03,\n",
       "        3.3185841e-03, 4.4048734e-02],\n",
       "       [3.3185841e-03, 4.4335419e-04, 5.7745418e-03, ..., 9.7146118e-01,\n",
       "        1.5306610e-03, 3.3185841e-03]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mir_calibrate(Z_val, onehot_encode(y_val), Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e3c92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.0259728e-09, 8.2769063e-09, 1.2163748e-06, ..., 2.0666739e-06,\n",
       "        1.6006267e-09, 4.6851145e-10],\n",
       "       [4.5414656e-04, 5.7007029e-04, 2.1136648e-06, ..., 1.6615165e-07,\n",
       "        9.9897248e-01, 7.9594372e-07],\n",
       "       [3.3712506e-05, 2.6184932e-07, 1.5655663e-08, ..., 1.1181473e-08,\n",
       "        9.9996275e-01, 3.1649208e-06],\n",
       "       ...,\n",
       "       [2.3110225e-08, 2.9416979e-08, 2.8897869e-06, ..., 2.3250170e-07,\n",
       "        1.2595495e-07, 6.8426665e-08],\n",
       "       [9.1244704e-01, 8.6053014e-02, 7.4484320e-05, ..., 6.6439623e-07,\n",
       "        1.0405089e-06, 2.0207855e-04],\n",
       "       [1.6639610e-06, 1.4131823e-08, 7.9446681e-06, ..., 9.9994475e-01,\n",
       "        3.8702217e-07, 1.3113222e-06]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(Z_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674722b",
   "metadata": {},
   "source": [
    "### Temperature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b699fa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54bfb3641487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlhaTempScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(25, 25))\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_train)\n",
    "ax[0, 0].hist(Ts, bins=50)\n",
    "ax[0, 0].set_xlabel('T', fontsize=22)\n",
    "ax[0, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_val)\n",
    "ax[0, 1].hist(Ts, bins=50)\n",
    "ax[0, 1].set_xlabel('T', fontsize=22)\n",
    "ax[0, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_test)\n",
    "ax[0, 2].hist(Ts, bins=50)\n",
    "ax[0, 2].set_xlabel('T', fontsize=22)\n",
    "ax[0, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_train)\n",
    "ax[1, 0].hist(Ts, bins=50)\n",
    "ax[1, 0].set_xlabel('T', fontsize=22)\n",
    "ax[1, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_val)\n",
    "ax[1, 1].hist(Ts, bins=50)\n",
    "ax[1, 1].set_xlabel('T', fontsize=22)\n",
    "ax[1, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_test)\n",
    "ax[1, 2].hist(Ts, bins=50)\n",
    "ax[1, 2].set_xlabel('T', fontsize=22)\n",
    "ax[1, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_train)\n",
    "ax[2, 0].hist(Ts, bins=50)\n",
    "ax[2, 0].set_xlabel('T', fontsize=22)\n",
    "ax[2, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_val)\n",
    "ax[2, 1].hist(Ts, bins=50)\n",
    "ax[2, 1].set_xlabel('T', fontsize=22)\n",
    "ax[2, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_test)\n",
    "ax[2, 2].hist(Ts, bins=50)\n",
    "ax[2, 2].set_xlabel('T', fontsize=22)\n",
    "ax[2, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20e79f",
   "metadata": {},
   "source": [
    "### Selected temperature for different confidences in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc, lc, hi, li = calib_split(Z_test, y_test)\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[hc | hi], y_test[hc | hi]);\n",
    "T_hc = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[lc | li], y_test[lc | li]);\n",
    "T_lc = ts_aux.T.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d48cbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TslH = lhaTempScaler.get_T(Z_test)\n",
    "TsDNN = dnnaTempScaler.get_T(Z_test)\n",
    "TsBDNN = bdnnaTempScaler.get_T(Z_test)\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(23, 25))\n",
    "\n",
    "\n",
    "ax[0, 0].hist(TslH[hc | hi])\n",
    "ax[0, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[0, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[hc | hi])), fontsize=26)\n",
    "ax[0, 0].legend(fontsize=18)\n",
    "\n",
    "ax[0, 1].hist(TslH[lc | li])\n",
    "ax[0, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[0, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[lc | li])), fontsize=26)\n",
    "ax[0, 1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[1, 0].hist(TsDNN[hc | hi])\n",
    "ax[1, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[1, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[hc | hi])), fontsize=26)\n",
    "ax[1, 0].legend(fontsize=18)\n",
    "\n",
    "ax[1, 1].hist(TsDNN[lc | li])\n",
    "ax[1, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[1, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[lc | li])), fontsize=26)\n",
    "ax[1, 1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[2, 0].hist(TsBDNN[hc | hi])\n",
    "ax[2, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[2, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[hc | hi])), fontsize=26)\n",
    "ax[2, 0].legend(fontsize=18)\n",
    "\n",
    "ax[2, 1].hist(TsBDNN[lc | li])\n",
    "ax[2, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[2, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[lc | li])), fontsize=26)\n",
    "ax[2, 1].legend(fontsize=18)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.yaxis.set_tick_params(labelleft=True)\n",
    "    _ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    _ax.set_xlabel('T', fontsize=22)\n",
    "    _ax.set_ylabel('Count', fontsize=22)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dec3a2",
   "metadata": {},
   "source": [
    "### According to quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ace34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = softmax(Z_test, axis=1)\n",
    "test_confs = np.max(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 8))\n",
    "\n",
    "ax.hist(test_confs, bins=200)\n",
    "\n",
    "ax.set_xlabel('Confidence', fontsize=22)\n",
    "ax.set_ylabel('Count', fontsize=22)\n",
    "ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.argsort(test_confs)\n",
    "\n",
    "q1, q2, q3, q4 = ix[:len(test_confs)//4], ix[len(test_confs)//4:len(test_confs)//2], ix[len(test_confs)//2: 3*len(test_confs)//4], ix[3*len(test_confs)//4:]\n",
    "\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q1], y_test[q1]);\n",
    "T_q1 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q2], y_test[q2]);\n",
    "T_q2 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q3], y_test[q3]);\n",
    "T_q3 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q4], y_test[q4]);\n",
    "T_q4 = ts_aux.T.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "TslH = lhaTempScaler.get_T(Z_test)\n",
    "TsDNN = dnnaTempScaler.get_T(Z_test)\n",
    "TsBDNN = bdnnaTempScaler.get_T(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, sharex=True, sharey=True, figsize=(30, 25))\n",
    "\n",
    "\n",
    "ax[0, 0].hist(TslH[q1])\n",
    "ax[0, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[0, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q1])), fontsize=26)\n",
    "\n",
    "ax[0, 1].hist(TslH[q2])\n",
    "ax[0, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[0, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q2])), fontsize=26)\n",
    "\n",
    "ax[0, 2].hist(TslH[q3])\n",
    "ax[0, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[0, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q3])), fontsize=26)\n",
    "\n",
    "ax[0, 3].hist(TslH[q4])\n",
    "ax[0, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[0, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "ax[1, 0].hist(TsDNN[q1])\n",
    "ax[1, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[1, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q1])), fontsize=26)\n",
    "\n",
    "ax[1, 1].hist(TsDNN[q2])\n",
    "ax[1, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[1, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q2])), fontsize=26)\n",
    "\n",
    "ax[1, 2].hist(TsDNN[q3])\n",
    "ax[1, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[1, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q3])), fontsize=26)\n",
    "\n",
    "ax[1, 3].hist(TsDNN[q4])\n",
    "ax[1, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[1, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "ax[2, 0].hist(TsBDNN[q1])\n",
    "ax[2, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[2, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q1])), fontsize=26)\n",
    "\n",
    "ax[2, 1].hist(TsBDNN[q2])\n",
    "ax[2, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[2, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q2])), fontsize=26)\n",
    "\n",
    "ax[2, 2].hist(TsBDNN[q3])\n",
    "ax[2, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[2, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q3])), fontsize=26)\n",
    "\n",
    "ax[2, 3].hist(TsBDNN[q4])\n",
    "ax[2, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[2, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.yaxis.set_tick_params(labelleft=True)\n",
    "    _ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.set_xlabel('T', fontsize=22)\n",
    "    _ax.set_ylabel('Count', fontsize=22)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea446d2c",
   "metadata": {},
   "source": [
    "## Corruption Robustness: CIFAR10-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38293ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c = get_CIFAR10_C(CIFAR10C_PATH)\n",
    "\n",
    "categories = list(cifar10c.keys())\n",
    "categories.remove('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d1bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_transforms_test=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8506f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = load_model('resnet50', 'cifar10', model_path='../../trained_models') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a92a32",
   "metadata": {},
   "source": [
    "### Robustness without exposure to corrupted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e84a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_logits = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_logits[category] = {}\n",
    "    print('Computing predictions for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        test_data = NumpyDataset(cifar10c[category][severity], cifar10c['labels'][:10000], transform=cifar10_transforms_test)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=256)\n",
    "        cifar10c_logits[category][severity] = predict_logits(net, test_dataloader, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_metrics_uncal = {}\n",
    "cifar10c_metrics_tscal = {}\n",
    "cifar10c_metrics_lhtscal = {}\n",
    "cifar10c_metrics_dnntscal = {}\n",
    "cifar10c_metrics_bdnntscal = {}\n",
    "cifar10c_metrics_histtscal = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_metrics_uncal[category] = {}\n",
    "    cifar10c_metrics_tscal[category] = {}\n",
    "    cifar10c_metrics_lhtscal[category] = {}\n",
    "    cifar10c_metrics_dnntscal[category] = {}\n",
    "    cifar10c_metrics_bdnntscal[category] = {}\n",
    "    cifar10c_metrics_histtscal[category] = {}\n",
    "    print('Computing metrics for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_metrics_uncal[category][severity] = compute_metrics(cifar10c_logits[category][severity], cifar10c['labels'][:10000])\n",
    "        cifar10c_metrics_tscal[category][severity] = compute_metrics(tempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_lhtscal[category][severity] = compute_metrics(lhaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_dnntscal[category][severity] = compute_metrics(dnnaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_bdnntscal[category][severity] = compute_metrics(bdnnaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_histtscal[category][severity] = compute_metrics(hisTS.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3dae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sev_uncal = np.zeros((5, 4))\n",
    "mean_sev_tscal = np.zeros((5, 4))\n",
    "mean_sev_lhtscal = np.zeros((5, 4))\n",
    "mean_sev_dnntscal = np.zeros((5, 4))\n",
    "mean_sev_bdnntscal = np.zeros((5, 4))\n",
    "mean_sev_histtscal = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_sev_uncal[i] += cifar10c_metrics_uncal[cat][i+1]\n",
    "        mean_sev_tscal[i] += cifar10c_metrics_tscal[cat][i+1]\n",
    "        mean_sev_lhtscal[i] += cifar10c_metrics_lhtscal[cat][i+1]\n",
    "        mean_sev_dnntscal[i] += cifar10c_metrics_dnntscal[cat][i+1]\n",
    "        mean_sev_bdnntscal[i] += cifar10c_metrics_bdnntscal[cat][i+1]\n",
    "        mean_sev_histtscal[i] += cifar10c_metrics_histtscal[cat][i+1]\n",
    "        \n",
    "mean_sev_uncal /= len(categories)\n",
    "mean_sev_tscal /= len(categories)\n",
    "mean_sev_lhtscal /= len(categories)\n",
    "mean_sev_dnntscal /= len(categories)\n",
    "mean_sev_bdnntscal /= len(categories)\n",
    "mean_sev_histtscal /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f61f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(28, 33))\n",
    "\n",
    "# ax[0].plot(mean_sev_uncal[:, 1], ls='--', marker='*', label='Uncalibrated')\n",
    "ax[0].plot(mean_sev_tscal[:, 1], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[0].plot(mean_sev_lhtscal[:, 1], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[0].plot(mean_sev_dnntscal[:, 1], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_bdnntscal[:, 1], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_histtscal[:, 1], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[0].set_ylabel('ECE', fontsize=22)\n",
    "\n",
    "# ax[1].plot(mnll_sev_uncal, label='Uncalibrated')\n",
    "ax[1].plot(mean_sev_tscal[:, 3], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[1].plot(mean_sev_lhtscal[:, 3], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[1].plot(mean_sev_dnntscal[:, 3], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_bdnntscal[:, 3], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_histtscal[:, 3], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[1].set_ylabel('NLL', fontsize=22)\n",
    "\n",
    "ax[2].plot(mean_sev_tscal[:, 2], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[2].plot(mean_sev_lhtscal[:, 2], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[2].plot(mean_sev_dnntscal[:, 2], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_bdnntscal[:, 2], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_histtscal[:, 2], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[2].set_ylabel('Brier Score', fontsize=22)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.set_xticks(np.arange(5))\n",
    "    _ax.set_xticklabels(np.arange(5) + 1)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    _ax.set_xlabel('Corruption level', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc51a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_TslH= {}\n",
    "cifar10c_TsDNN= {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_TslH[category] = {}\n",
    "    cifar10c_TsDNN[category] = {}\n",
    "    print('Computing Ts for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_TslH[category][severity] = lhaTempScaler.get_T(cifar10c_logits[category][severity])\n",
    "        cifar10c_TsDNN[category][severity] = dnnaTempScaler.get_T(cifar10c_logits[category][severity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cbde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_TslH = np.zeros(5)\n",
    "mean_TsDNN = np.zeros(5)\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_TslH[i] += np.mean(cifar10c_TslH[cat][i+1])\n",
    "        mean_TsDNN[i] += np.mean(cifar10c_TsDNN[cat][i+1])\n",
    "        \n",
    "mean_TslH /= len(categories)\n",
    "mean_TsDNN /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_TslH)\n",
    "print(mean_TsDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0185e8",
   "metadata": {},
   "source": [
    "### Exposure to corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba07264",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = np.random.permutation(10000)\n",
    "idx_train = rnd_idx[:3000]\n",
    "idx_test = rnd_idx[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa96aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.vstack([cifar10c_logits[cat][i+1][idx_train] for cat in categories for i in range(5)])\n",
    "y_train = np.hstack([cifar10c['labels'][idx_train] for cat in categories for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d52553",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temp-Scal as baseline:\n",
    "tempScaler = TempScaling()\n",
    "tempScaler.fit(train_set, y_train, v=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhaTempScaler = AdaTS(HlogbasedT(dim))\n",
    "lhaTempScaler = fitAdaTS(lhaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd694d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnaTempScaler = AdaTS(DNNbasedT(dim))\n",
    "dnnaTempScaler = fitAdaTS(dnnaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eafd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdnnaTempScaler = AdaTS(DNNbasedT(dim, hs=[2*dim, 2*dim]))\n",
    "bdnnaTempScaler = fitAdaTS(bdnnaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ae8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hisTS = HistTS()\n",
    "hisTS.fit(train_set, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42895b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_metrics_uncal = {}\n",
    "cifar10c_metrics_tscal = {}\n",
    "cifar10c_metrics_lhtscal = {}\n",
    "cifar10c_metrics_dnntscal = {}\n",
    "cifar10c_metrics_bdnntscal = {}\n",
    "cifar10c_metrics_histtscal = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_metrics_uncal[category] = {}\n",
    "    cifar10c_metrics_tscal[category] = {}\n",
    "    cifar10c_metrics_lhtscal[category] = {}\n",
    "    cifar10c_metrics_dnntscal[category] = {}\n",
    "    cifar10c_metrics_bdnntscal[category] = {}\n",
    "    cifar10c_metrics_histtscal[category] = {}\n",
    "    print('Computing metrics for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_metrics_uncal[category][severity] = compute_metrics(cifar10c_logits[category][severity][idx_test], cifar10c['labels'][idx_test])\n",
    "        cifar10c_metrics_tscal[category][severity] = compute_metrics(tempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_lhtscal[category][severity] = compute_metrics(lhaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_dnntscal[category][severity] = compute_metrics(dnnaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_bdnntscal[category][severity] = compute_metrics(bdnnaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_histtscal[category][severity] = compute_metrics(hisTS.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724622b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sev_uncal = np.zeros((5, 4))\n",
    "mean_sev_tscal = np.zeros((5, 4))\n",
    "mean_sev_lhtscal = np.zeros((5, 4))\n",
    "mean_sev_dnntscal = np.zeros((5, 4))\n",
    "mean_sev_bdnntscal = np.zeros((5, 4))\n",
    "mean_sev_histtscal = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_sev_uncal[i] += cifar10c_metrics_uncal[cat][i+1]\n",
    "        mean_sev_tscal[i] += cifar10c_metrics_tscal[cat][i+1]\n",
    "        mean_sev_lhtscal[i] += cifar10c_metrics_lhtscal[cat][i+1]\n",
    "        mean_sev_dnntscal[i] += cifar10c_metrics_dnntscal[cat][i+1]\n",
    "        mean_sev_bdnntscal[i] += cifar10c_metrics_bdnntscal[cat][i+1]\n",
    "        mean_sev_histtscal[i] += cifar10c_metrics_histtscal[cat][i+1]\n",
    "        \n",
    "mean_sev_uncal /= len(categories)\n",
    "mean_sev_tscal /= len(categories)\n",
    "mean_sev_lhtscal /= len(categories)\n",
    "mean_sev_dnntscal /= len(categories)\n",
    "mean_sev_bdnntscal /= len(categories)\n",
    "mean_sev_histtscal /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff5b89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(28, 33))\n",
    "\n",
    "# ax[0].plot(mean_sev_uncal[:, 1], ls='--', marker='*', label='Uncalibrated')\n",
    "ax[0].plot(mean_sev_tscal[:, 1], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[0].plot(mean_sev_lhtscal[:, 1], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[0].plot(mean_sev_dnntscal[:, 1], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_bdnntscal[:, 1], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_histtscal[:, 1], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[0].set_ylabel('ECE', fontsize=22)\n",
    "\n",
    "# ax[1].plot(mnll_sev_uncal, label='Uncalibrated')\n",
    "ax[1].plot(mean_sev_tscal[:, 3], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[1].plot(mean_sev_lhtscal[:, 3], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[1].plot(mean_sev_dnntscal[:, 3], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_bdnntscal[:, 3], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_histtscal[:, 3], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[1].set_ylabel('NLL', fontsize=22)\n",
    "\n",
    "ax[2].plot(mean_sev_tscal[:, 2], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[2].plot(mean_sev_lhtscal[:, 2], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[2].plot(mean_sev_dnntscal[:, 2], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_bdnntscal[:, 2], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_histtscal[:, 2], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[2].set_ylabel('Brier Score', fontsize=22)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.set_xticks(np.arange(5))\n",
    "    _ax.set_xticklabels(np.arange(5) + 1)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    _ax.set_xlabel('Corruption level', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63507f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
