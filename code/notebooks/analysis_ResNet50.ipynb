{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of AdaTempScal on ResNet50 for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.extend(['..'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from models import AdaTS, TempScaling, HlogbasedT, DNNbasedT, HistTS, EnsembleTS, BTS\n",
    "%aimport utils\n",
    "from utils import compare_results, calib_split, get_CIFAR10_C, NumpyDataset, load_model, predict_logits, compute_metrics, onehot_encode\n",
    "%aimport adats_utils\n",
    "from adats_utils import fitAdaTS, fitCV_AdaTS, fitHistTS\n",
    "%aimport mixNmatch_cal\n",
    "from mixNmatch_cal import ets_calibrate, mir_calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath} \\usepackage{amssymb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and precomputed logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_PATH = '../../data/CIFAR10'\n",
    "CIFAR10C_PATH = '../../data/CIFAR-10-C'\n",
    "MODEL_PATH = '../../trained_models/CIFAR10/resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(CIFAR10_PATH, 'train_imas.npy'))\n",
    "y_train = np.load(os.path.join(CIFAR10_PATH, 'train_labels.npy'))\n",
    "\n",
    "X_val = np.load(os.path.join(CIFAR10_PATH, 'val_imas.npy'))\n",
    "y_val = np.load(os.path.join(CIFAR10_PATH, 'val_labels.npy'))\n",
    "\n",
    "X_test = np.load(os.path.join(CIFAR10_PATH, 'test_imas.npy'))\n",
    "y_test = np.load(os.path.join(CIFAR10_PATH, 'test_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = np.load(os.path.join(MODEL_PATH, 'train_logits.npy'))\n",
    "Z_val = np.load(os.path.join(MODEL_PATH, 'val_logits.npy'))\n",
    "Z_test = np.load(os.path.join(MODEL_PATH, 'test_logits.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 784, NLL: 2.172e+03, Temp: 2.575, at time: 2.34s\r"
     ]
    }
   ],
   "source": [
    "N, dim = Z_train.shape\n",
    "\n",
    "### Temp-Scal as baseline:\n",
    "tempScaler = TempScaling()\n",
    "tempScaler.fit(Z_val, y_val, v=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 19994, NLL: 2.152e+03, at time: 263.41s\r"
     ]
    }
   ],
   "source": [
    "lhaTempScaler = AdaTS(HlogbasedT(dim))\n",
    "lhaTempScaler = fitAdaTS(lhaTempScaler, Z_val, y_val, epochs=20000, batch_size=1000, lr=1e-3, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 21674, NLL: 2.136e+03, at time: 491.42s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-73885de5cac6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdnnaTempScaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaTS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDNNbasedT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdnnaTempScaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitAdaTS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdnnaTempScaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\repos\\adaptive-tempscaling\\code\\adats_utils.py\u001b[0m in \u001b[0;36mfitAdaTS\u001b[1;34m(adaTS, X, Y, epochs, batch_size, lr, optimizer, weight_decay, v, target_file, dev)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0m_nll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mnll\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_nll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\calibration\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\calibration\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m                     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dnnaTempScaler = AdaTS(DNNbasedT(dim))\n",
    "dnnaTempScaler = fitAdaTS(dnnaTempScaler, Z_val, y_val, epochs=30000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTS = AdaTS(DNNbasedT(dim, hs=[5, 5]))\n",
    "PTS = fitAdaTS(PTS, Z_val, y_val, epochs=30000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisTS = HistTS()\n",
    "hisTS.fit(Z_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts = BTS()\n",
    "bts.fit(Z_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##### Results on train set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_train, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_train),\n",
    "                             'BTS': bts.predictive(Z_train),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_train, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_train),\n",
    "                             'logH-TempScal': lhaTempScaler.predictive(Z_train),\n",
    "                             'DNN-TempScal': dnnaTempScaler.predictive(Z_train),\n",
    "                             'PTS': PTS.predictive(Z_train),\n",
    "                             'HistH-TempScal': hisTS.predictive(Z_train)}, target=y_train, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##### Results on validation set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_val, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_val),\n",
    "                             'BTS': bts.predictive(Z_val),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_val, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_val),\n",
    "                             'logH-TempScal': lhaTempScaler.predictive(Z_val),\n",
    "                             'DNN-TempScal': dnnaTempScaler.predictive(Z_val),\n",
    "                             'PTS': PTS.predictive(Z_val),\n",
    "                             'HistH-TempScal': hisTS.predictive(Z_val)}, target=y_val, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##### Results on test set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_test, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_test),\n",
    "                             'BTS': bts.predictive(Z_test),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_test, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_test),\n",
    "                             'logH-TempScal': lhaTempScaler.predictive(Z_test),\n",
    "                             'DNN-TempScal': dnnaTempScaler.predictive(Z_test),\n",
    "                             'PTS': PTS.predictive(Z_test),\n",
    "                             'HistH-TempScal': hisTS.predictive(Z_test)}, target=y_test, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54bfb3641487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlhaTempScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(25, 25))\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_train)\n",
    "ax[0, 0].hist(Ts, bins=50)\n",
    "ax[0, 0].set_xlabel('T', fontsize=22)\n",
    "ax[0, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_val)\n",
    "ax[0, 1].hist(Ts, bins=50)\n",
    "ax[0, 1].set_xlabel('T', fontsize=22)\n",
    "ax[0, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_test)\n",
    "ax[0, 2].hist(Ts, bins=50)\n",
    "ax[0, 2].set_xlabel('T', fontsize=22)\n",
    "ax[0, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_train)\n",
    "ax[1, 0].hist(Ts, bins=50)\n",
    "ax[1, 0].set_xlabel('T', fontsize=22)\n",
    "ax[1, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_val)\n",
    "ax[1, 1].hist(Ts, bins=50)\n",
    "ax[1, 1].set_xlabel('T', fontsize=22)\n",
    "ax[1, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_test)\n",
    "ax[1, 2].hist(Ts, bins=50)\n",
    "ax[1, 2].set_xlabel('T', fontsize=22)\n",
    "ax[1, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_train)\n",
    "ax[2, 0].hist(Ts, bins=50)\n",
    "ax[2, 0].set_xlabel('T', fontsize=22)\n",
    "ax[2, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_val)\n",
    "ax[2, 1].hist(Ts, bins=50)\n",
    "ax[2, 1].set_xlabel('T', fontsize=22)\n",
    "ax[2, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_test)\n",
    "ax[2, 2].hist(Ts, bins=50)\n",
    "ax[2, 2].set_xlabel('T', fontsize=22)\n",
    "ax[2, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected temperature for different confidences in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc, lc, hi, li = calib_split(Z_test, y_test)\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[hc | hi], y_test[hc | hi]);\n",
    "T_hc = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[lc | li], y_test[lc | li]);\n",
    "T_lc = ts_aux.T.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TslH = lhaTempScaler.get_T(Z_test)\n",
    "TsDNN = dnnaTempScaler.get_T(Z_test)\n",
    "TsBDNN = bdnnaTempScaler.get_T(Z_test)\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(23, 25))\n",
    "\n",
    "\n",
    "ax[0, 0].hist(TslH[hc | hi])\n",
    "ax[0, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[0, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[hc | hi])), fontsize=26)\n",
    "ax[0, 0].legend(fontsize=18)\n",
    "\n",
    "ax[0, 1].hist(TslH[lc | li])\n",
    "ax[0, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[0, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[lc | li])), fontsize=26)\n",
    "ax[0, 1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[1, 0].hist(TsDNN[hc | hi])\n",
    "ax[1, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[1, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[hc | hi])), fontsize=26)\n",
    "ax[1, 0].legend(fontsize=18)\n",
    "\n",
    "ax[1, 1].hist(TsDNN[lc | li])\n",
    "ax[1, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[1, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[lc | li])), fontsize=26)\n",
    "ax[1, 1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[2, 0].hist(TsBDNN[hc | hi])\n",
    "ax[2, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[2, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[hc | hi])), fontsize=26)\n",
    "ax[2, 0].legend(fontsize=18)\n",
    "\n",
    "ax[2, 1].hist(TsBDNN[lc | li])\n",
    "ax[2, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[2, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[lc | li])), fontsize=26)\n",
    "ax[2, 1].legend(fontsize=18)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.yaxis.set_tick_params(labelleft=True)\n",
    "    _ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    _ax.set_xlabel('T', fontsize=22)\n",
    "    _ax.set_ylabel('Count', fontsize=22)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = softmax(Z_test, axis=1)\n",
    "test_confs = np.max(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 8))\n",
    "\n",
    "ax.hist(test_confs, bins=200)\n",
    "\n",
    "ax.set_xlabel('Confidence', fontsize=22)\n",
    "ax.set_ylabel('Count', fontsize=22)\n",
    "ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.argsort(test_confs)\n",
    "\n",
    "q1, q2, q3, q4 = ix[:len(test_confs)//4], ix[len(test_confs)//4:len(test_confs)//2], ix[len(test_confs)//2: 3*len(test_confs)//4], ix[3*len(test_confs)//4:]\n",
    "\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q1], y_test[q1]);\n",
    "T_q1 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q2], y_test[q2]);\n",
    "T_q2 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q3], y_test[q3]);\n",
    "T_q3 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q4], y_test[q4]);\n",
    "T_q4 = ts_aux.T.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "TslH = lhaTempScaler.get_T(Z_test)\n",
    "TsDNN = dnnaTempScaler.get_T(Z_test)\n",
    "TsBDNN = bdnnaTempScaler.get_T(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, sharex=True, sharey=True, figsize=(30, 25))\n",
    "\n",
    "\n",
    "ax[0, 0].hist(TslH[q1])\n",
    "ax[0, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[0, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q1])), fontsize=26)\n",
    "\n",
    "ax[0, 1].hist(TslH[q2])\n",
    "ax[0, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[0, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q2])), fontsize=26)\n",
    "\n",
    "ax[0, 2].hist(TslH[q3])\n",
    "ax[0, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[0, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q3])), fontsize=26)\n",
    "\n",
    "ax[0, 3].hist(TslH[q4])\n",
    "ax[0, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[0, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "ax[1, 0].hist(TsDNN[q1])\n",
    "ax[1, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[1, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q1])), fontsize=26)\n",
    "\n",
    "ax[1, 1].hist(TsDNN[q2])\n",
    "ax[1, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[1, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q2])), fontsize=26)\n",
    "\n",
    "ax[1, 2].hist(TsDNN[q3])\n",
    "ax[1, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[1, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q3])), fontsize=26)\n",
    "\n",
    "ax[1, 3].hist(TsDNN[q4])\n",
    "ax[1, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[1, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "ax[2, 0].hist(TsBDNN[q1])\n",
    "ax[2, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[2, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q1])), fontsize=26)\n",
    "\n",
    "ax[2, 1].hist(TsBDNN[q2])\n",
    "ax[2, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[2, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q2])), fontsize=26)\n",
    "\n",
    "ax[2, 2].hist(TsBDNN[q3])\n",
    "ax[2, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[2, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q3])), fontsize=26)\n",
    "\n",
    "ax[2, 3].hist(TsBDNN[q4])\n",
    "ax[2, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[2, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.yaxis.set_tick_params(labelleft=True)\n",
    "    _ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.set_xlabel('T', fontsize=22)\n",
    "    _ax.set_ylabel('Count', fontsize=22)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corruption Robustness: CIFAR10-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c = get_CIFAR10_C(CIFAR10C_PATH)\n",
    "\n",
    "categories = list(cifar10c.keys())\n",
    "categories.remove('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_transforms_test=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = load_model('resnet50', 'cifar10', model_path='../../trained_models') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness without exposure to corrupted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_logits = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_logits[category] = {}\n",
    "    print('Computing predictions for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        test_data = NumpyDataset(cifar10c[category][severity], cifar10c['labels'][:10000], transform=cifar10_transforms_test)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=256)\n",
    "        cifar10c_logits[category][severity] = predict_logits(net, test_dataloader, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_metrics_uncal = {}\n",
    "cifar10c_metrics_tscal = {}\n",
    "cifar10c_metrics_lhtscal = {}\n",
    "cifar10c_metrics_dnntscal = {}\n",
    "cifar10c_metrics_bdnntscal = {}\n",
    "cifar10c_metrics_histtscal = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_metrics_uncal[category] = {}\n",
    "    cifar10c_metrics_tscal[category] = {}\n",
    "    cifar10c_metrics_lhtscal[category] = {}\n",
    "    cifar10c_metrics_dnntscal[category] = {}\n",
    "    cifar10c_metrics_bdnntscal[category] = {}\n",
    "    cifar10c_metrics_histtscal[category] = {}\n",
    "    print('Computing metrics for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_metrics_uncal[category][severity] = compute_metrics(cifar10c_logits[category][severity], cifar10c['labels'][:10000])\n",
    "        cifar10c_metrics_tscal[category][severity] = compute_metrics(tempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_lhtscal[category][severity] = compute_metrics(lhaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_dnntscal[category][severity] = compute_metrics(dnnaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_bdnntscal[category][severity] = compute_metrics(bdnnaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_histtscal[category][severity] = compute_metrics(hisTS.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sev_uncal = np.zeros((5, 4))\n",
    "mean_sev_tscal = np.zeros((5, 4))\n",
    "mean_sev_lhtscal = np.zeros((5, 4))\n",
    "mean_sev_dnntscal = np.zeros((5, 4))\n",
    "mean_sev_bdnntscal = np.zeros((5, 4))\n",
    "mean_sev_histtscal = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_sev_uncal[i] += cifar10c_metrics_uncal[cat][i+1]\n",
    "        mean_sev_tscal[i] += cifar10c_metrics_tscal[cat][i+1]\n",
    "        mean_sev_lhtscal[i] += cifar10c_metrics_lhtscal[cat][i+1]\n",
    "        mean_sev_dnntscal[i] += cifar10c_metrics_dnntscal[cat][i+1]\n",
    "        mean_sev_bdnntscal[i] += cifar10c_metrics_bdnntscal[cat][i+1]\n",
    "        mean_sev_histtscal[i] += cifar10c_metrics_histtscal[cat][i+1]\n",
    "        \n",
    "mean_sev_uncal /= len(categories)\n",
    "mean_sev_tscal /= len(categories)\n",
    "mean_sev_lhtscal /= len(categories)\n",
    "mean_sev_dnntscal /= len(categories)\n",
    "mean_sev_bdnntscal /= len(categories)\n",
    "mean_sev_histtscal /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(28, 33))\n",
    "\n",
    "# ax[0].plot(mean_sev_uncal[:, 1], ls='--', marker='*', label='Uncalibrated')\n",
    "ax[0].plot(mean_sev_tscal[:, 1], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[0].plot(mean_sev_lhtscal[:, 1], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[0].plot(mean_sev_dnntscal[:, 1], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_bdnntscal[:, 1], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_histtscal[:, 1], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[0].set_ylabel('ECE', fontsize=22)\n",
    "\n",
    "# ax[1].plot(mnll_sev_uncal, label='Uncalibrated')\n",
    "ax[1].plot(mean_sev_tscal[:, 3], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[1].plot(mean_sev_lhtscal[:, 3], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[1].plot(mean_sev_dnntscal[:, 3], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_bdnntscal[:, 3], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_histtscal[:, 3], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[1].set_ylabel('NLL', fontsize=22)\n",
    "\n",
    "ax[2].plot(mean_sev_tscal[:, 2], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[2].plot(mean_sev_lhtscal[:, 2], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[2].plot(mean_sev_dnntscal[:, 2], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_bdnntscal[:, 2], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_histtscal[:, 2], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[2].set_ylabel('Brier Score', fontsize=22)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.set_xticks(np.arange(5))\n",
    "    _ax.set_xticklabels(np.arange(5) + 1)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    _ax.set_xlabel('Corruption level', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_TslH= {}\n",
    "cifar10c_TsDNN= {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_TslH[category] = {}\n",
    "    cifar10c_TsDNN[category] = {}\n",
    "    print('Computing Ts for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_TslH[category][severity] = lhaTempScaler.get_T(cifar10c_logits[category][severity])\n",
    "        cifar10c_TsDNN[category][severity] = dnnaTempScaler.get_T(cifar10c_logits[category][severity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_TslH = np.zeros(5)\n",
    "mean_TsDNN = np.zeros(5)\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_TslH[i] += np.mean(cifar10c_TslH[cat][i+1])\n",
    "        mean_TsDNN[i] += np.mean(cifar10c_TsDNN[cat][i+1])\n",
    "        \n",
    "mean_TslH /= len(categories)\n",
    "mean_TsDNN /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_TslH)\n",
    "print(mean_TsDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exposure to corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = np.random.permutation(10000)\n",
    "idx_train = rnd_idx[:3000]\n",
    "idx_test = rnd_idx[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.vstack([cifar10c_logits[cat][i+1][idx_train] for cat in categories for i in range(5)])\n",
    "y_train = np.hstack([cifar10c['labels'][idx_train] for cat in categories for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temp-Scal as baseline:\n",
    "tempScaler = TempScaling()\n",
    "tempScaler.fit(train_set, y_train, v=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhaTempScaler = AdaTS(HlogbasedT(dim))\n",
    "lhaTempScaler = fitAdaTS(lhaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnaTempScaler = AdaTS(DNNbasedT(dim))\n",
    "dnnaTempScaler = fitAdaTS(dnnaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdnnaTempScaler = AdaTS(DNNbasedT(dim, hs=[2*dim, 2*dim]))\n",
    "bdnnaTempScaler = fitAdaTS(bdnnaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisTS = HistTS()\n",
    "hisTS.fit(train_set, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_metrics_uncal = {}\n",
    "cifar10c_metrics_tscal = {}\n",
    "cifar10c_metrics_lhtscal = {}\n",
    "cifar10c_metrics_dnntscal = {}\n",
    "cifar10c_metrics_bdnntscal = {}\n",
    "cifar10c_metrics_histtscal = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_metrics_uncal[category] = {}\n",
    "    cifar10c_metrics_tscal[category] = {}\n",
    "    cifar10c_metrics_lhtscal[category] = {}\n",
    "    cifar10c_metrics_dnntscal[category] = {}\n",
    "    cifar10c_metrics_bdnntscal[category] = {}\n",
    "    cifar10c_metrics_histtscal[category] = {}\n",
    "    print('Computing metrics for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_metrics_uncal[category][severity] = compute_metrics(cifar10c_logits[category][severity][idx_test], cifar10c['labels'][idx_test])\n",
    "        cifar10c_metrics_tscal[category][severity] = compute_metrics(tempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_lhtscal[category][severity] = compute_metrics(lhaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_dnntscal[category][severity] = compute_metrics(dnnaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_bdnntscal[category][severity] = compute_metrics(bdnnaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_histtscal[category][severity] = compute_metrics(hisTS.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sev_uncal = np.zeros((5, 4))\n",
    "mean_sev_tscal = np.zeros((5, 4))\n",
    "mean_sev_lhtscal = np.zeros((5, 4))\n",
    "mean_sev_dnntscal = np.zeros((5, 4))\n",
    "mean_sev_bdnntscal = np.zeros((5, 4))\n",
    "mean_sev_histtscal = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_sev_uncal[i] += cifar10c_metrics_uncal[cat][i+1]\n",
    "        mean_sev_tscal[i] += cifar10c_metrics_tscal[cat][i+1]\n",
    "        mean_sev_lhtscal[i] += cifar10c_metrics_lhtscal[cat][i+1]\n",
    "        mean_sev_dnntscal[i] += cifar10c_metrics_dnntscal[cat][i+1]\n",
    "        mean_sev_bdnntscal[i] += cifar10c_metrics_bdnntscal[cat][i+1]\n",
    "        mean_sev_histtscal[i] += cifar10c_metrics_histtscal[cat][i+1]\n",
    "        \n",
    "mean_sev_uncal /= len(categories)\n",
    "mean_sev_tscal /= len(categories)\n",
    "mean_sev_lhtscal /= len(categories)\n",
    "mean_sev_dnntscal /= len(categories)\n",
    "mean_sev_bdnntscal /= len(categories)\n",
    "mean_sev_histtscal /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(28, 33))\n",
    "\n",
    "# ax[0].plot(mean_sev_uncal[:, 1], ls='--', marker='*', label='Uncalibrated')\n",
    "ax[0].plot(mean_sev_tscal[:, 1], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[0].plot(mean_sev_lhtscal[:, 1], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[0].plot(mean_sev_dnntscal[:, 1], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_bdnntscal[:, 1], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_histtscal[:, 1], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[0].set_ylabel('ECE', fontsize=22)\n",
    "\n",
    "# ax[1].plot(mnll_sev_uncal, label='Uncalibrated')\n",
    "ax[1].plot(mean_sev_tscal[:, 3], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[1].plot(mean_sev_lhtscal[:, 3], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[1].plot(mean_sev_dnntscal[:, 3], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_bdnntscal[:, 3], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_histtscal[:, 3], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[1].set_ylabel('NLL', fontsize=22)\n",
    "\n",
    "ax[2].plot(mean_sev_tscal[:, 2], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[2].plot(mean_sev_lhtscal[:, 2], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[2].plot(mean_sev_dnntscal[:, 2], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_bdnntscal[:, 2], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_histtscal[:, 2], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[2].set_ylabel('Brier Score', fontsize=22)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.set_xticks(np.arange(5))\n",
    "    _ax.set_xticklabels(np.arange(5) + 1)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    _ax.set_xlabel('Corruption level', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
