{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f3299f",
   "metadata": {},
   "source": [
    "# Analysis of AdaTempScal on ResNet50 for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6c18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce67d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10198579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.extend(['..'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from mixNmatch_cal import temperature_scaling\n",
    "from scipy_models import LTS, HTS, HistTS, TS, HnLTS, BTS\n",
    "from models import AdaTS, DNNbasedT\n",
    "from models import LTS as LTS_torch\n",
    "from models import HTS as HTS_torch\n",
    "from models import HnLTS as HnLTS_torch\n",
    "%aimport utils\n",
    "from utils import compare_results, calib_split, get_CIFAR10_C, NumpyDataset, load_model, predict_logits, compute_metrics, onehot_encode, softmax\n",
    "%aimport adats_utils\n",
    "from adats_utils import fitAdaTS, fitCV_AdaTS, fitHistTS\n",
    "%aimport mixNmatch_cal\n",
    "from mixNmatch_cal import ets_calibrate, mir_calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2651d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4f116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath} \\usepackage{amssymb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f05d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c7b34d",
   "metadata": {},
   "source": [
    "## Load data and precomputed logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3649e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_PATH = '../../data/CIFAR10'\n",
    "CIFAR10C_PATH = '../../data/CIFAR-10-C'\n",
    "MODEL_PATH = '../../trained_models/CIFAR10/resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a18fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(CIFAR10_PATH, 'train_imas.npy'))\n",
    "y_train = np.load(os.path.join(CIFAR10_PATH, 'train_labels.npy'))\n",
    "\n",
    "X_val = np.load(os.path.join(CIFAR10_PATH, 'val_imas.npy'))\n",
    "y_val = np.load(os.path.join(CIFAR10_PATH, 'val_labels.npy'))\n",
    "\n",
    "X_test = np.load(os.path.join(CIFAR10_PATH, 'test_imas.npy'))\n",
    "y_test = np.load(os.path.join(CIFAR10_PATH, 'test_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "586f99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = np.load(os.path.join(MODEL_PATH, 'train_logits.npy'))\n",
    "Z_val = np.load(os.path.join(MODEL_PATH, 'val_logits.npy'))\n",
    "Z_test = np.load(os.path.join(MODEL_PATH, 'test_logits.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552d34d",
   "metadata": {},
   "source": [
    "### Calibrate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd7882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2171.642972\n",
      "         Iterations: 7\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n"
     ]
    }
   ],
   "source": [
    "N, dim = Z_train.shape\n",
    "\n",
    "### Temp-Scal as baseline:\n",
    "tempScaler = TS(dim)\n",
    "tempScaler.fit(Z_val, y_val, v=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "622f316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 2152.374124\n",
      "         Iterations: 11\n",
      "         Function evaluations: 53\n",
      "         Gradient evaluations: 47\n"
     ]
    }
   ],
   "source": [
    "hts = HTS(dim)\n",
    "hts.fit(Z_val, y_val, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d466328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training, convergence reached. NLL: 2153.31 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hts_t = AdaTS(HTS_torch(dim))\n",
    "hts_t = fitAdaTS(hts_t, Z_val, y_val, epochs=30000, batch_size=1000, lr=1e-3, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81256d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2138.376580\n",
      "         Iterations: 37\n",
      "         Function evaluations: 48\n",
      "         Gradient evaluations: 48\n"
     ]
    }
   ],
   "source": [
    "lts = LTS(dim)\n",
    "lts.fit(Z_val, y_val, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5dc7414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training, convergence reached. NLL: 2140.47 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lts_t = AdaTS(LTS_torch(dim))\n",
    "lts_t = fitAdaTS(lts_t, Z_val, y_val, epochs=30000, batch_size=1000, lr=1e-4, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ad4669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 2123.963216\n",
      "         Iterations: 44\n",
      "         Function evaluations: 145\n",
      "         Gradient evaluations: 130\n"
     ]
    }
   ],
   "source": [
    "hlts = HnLTS(dim)\n",
    "hlts.fit(Z_val, y_val, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c83c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training, convergence reached. NLL: 2131.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hlts_t = AdaTS(HnLTS_torch(dim))\n",
    "hlts_t = fitAdaTS(hlts_t, Z_val, y_val, epochs=30000, batch_size=1000, lr=1e-4, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ffe5ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted bin 49, with T: 2.40\r"
     ]
    }
   ],
   "source": [
    "bts = BTS()\n",
    "bts.fit(Z_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "173f6c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training, convergence reached. NLL: 2135.10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "PTS = AdaTS(DNNbasedT(dim, hs=[5, 5]))\n",
    "PTS = fitAdaTS(PTS, Z_val, y_val, epochs=30000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c48d5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "hisTS = HistTS()\n",
    "hisTS.fit(Z_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec0a8c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on train set:\n",
      "  Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal                99.94%         0.12%        47.21%    1.104e-03     2.701e-03\n",
      "TempScal             99.94%         5.36%        71.37%    8.604e-03     5.812e-02\n",
      "BTS                  99.94%         4.75%        72.62%    1.003e-02     5.309e-02\n",
      "ETS                  99.94%         7.37%        72.93%    1.287e-02     8.031e-02\n",
      "MIR                  99.94%         5.06%        78.27%    1.103e-02     5.635e-02\n",
      "HTS                  99.94%         4.79%        74.31%    9.582e-03     5.312e-02\n",
      "HTS_torch            99.94%         4.74%        73.62%    9.026e-03     5.224e-02\n",
      "LTS                  99.94%         5.30%        72.10%    9.451e-03     5.806e-02\n",
      "LTS_torch            99.94%         4.88%        71.81%    8.657e-03     5.350e-02\n",
      "HnLTS                99.94%         4.78%        74.61%    1.010e-02     5.330e-02\n",
      "HnLTS_torch          99.94%         4.73%        72.84%    8.936e-03     5.214e-02\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on train set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_train, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_train),\n",
    "                             'BTS': bts.predictive(Z_train),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_train, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_train),\n",
    "                             'HTS': hts.predictive(Z_train),\n",
    "                             'HTS_torch': hts_t.predictive(Z_train),\n",
    "                             'LTS': lts.predictive(Z_train),\n",
    "                             'LTS_torch': lts_t.predictive(Z_train),\n",
    "                             'HnLTS': hlts.predictive(Z_train),\n",
    "                             'HnLTS_torch': hlts_t.predictive(Z_train)}, target=y_train, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "223b87eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on val set:\n",
      "  Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal                86.72%        10.31%        73.80%    2.300e-01     7.737e-01\n",
      "TempScal             86.72%         3.06%        79.67%    1.967e-01     4.343e-01\n",
      "BTS                  86.72%         2.20%        80.17%    1.938e-01     4.275e-01\n",
      "ETS                  86.72%         3.40%        80.22%    1.958e-01     4.382e-01\n",
      "MIR                  86.72%         1.50%        82.23%    1.935e-01     4.212e-01\n",
      "HTS                  86.72%         2.16%        80.79%    1.953e-01     4.305e-01\n",
      "HTS_torch            86.72%         2.32%        80.52%    1.956e-01     4.307e-01\n",
      "LTS                  86.72%         2.85%        78.74%    1.946e-01     4.277e-01\n",
      "LTS_torch            86.72%         2.81%        78.64%    1.951e-01     4.281e-01\n",
      "HnLTS                86.72%         2.12%        79.88%    1.937e-01     4.248e-01\n",
      "HnLTS_torch          86.72%         2.56%        79.10%    1.945e-01     4.262e-01\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on val set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_val, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_val),\n",
    "                             'BTS': bts.predictive(Z_val),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_val, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_val),\n",
    "                             'HTS': hts.predictive(Z_val),\n",
    "                             'HTS_torch': hts_t.predictive(Z_val),\n",
    "                             'LTS': lts.predictive(Z_val),\n",
    "                             'LTS_torch': lts_t.predictive(Z_val),\n",
    "                             'HnLTS': hlts.predictive(Z_val),\n",
    "                             'HnLTS_torch': hlts_t.predictive(Z_val)}, target=y_val, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ac47961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results on test set:\n",
      "  Calibrator      Accuracy           ECE           MCE   Brier Score           NLL\n",
      "Uncal                86.13%        10.71%        49.03%    2.392e-01     7.897e-01\n",
      "TempScal             86.13%         2.54%        51.53%    2.037e-01     4.473e-01\n",
      "BTS                  86.13%         1.86%        60.38%    2.036e-01     4.498e-01\n",
      "ETS                  86.13%         2.84%        43.68%    2.029e-01     4.515e-01\n",
      "MIR                  86.13%         1.19%        80.73%    2.022e-01     4.432e-01\n",
      "HTS                  86.13%         1.45%        45.16%    2.024e-01     4.448e-01\n",
      "HTS_torch            86.13%         1.41%        78.25%    2.026e-01     4.447e-01\n",
      "LTS                  86.13%         2.52%        36.64%    2.019e-01     4.400e-01\n",
      "LTS_torch            86.13%         2.53%        36.42%    2.023e-01     4.400e-01\n",
      "HnLTS                86.13%         1.58%        45.22%    2.011e-01     4.387e-01\n",
      "HnLTS_torch          86.13%         2.27%        43.58%    2.018e-01     4.388e-01\n"
     ]
    }
   ],
   "source": [
    "print('##### Results on test set:')\n",
    "compare_results(predictions={'Uncal': softmax(Z_test, axis=1),\n",
    "                             'TempScal': tempScaler.predictive(Z_test),\n",
    "                             'BTS': bts.predictive(Z_test),\n",
    "                             'ETS': ets_calibrate(Z_val, onehot_encode(y_val), Z_test, dim),\n",
    "                             'MIR': mir_calibrate(Z_val, onehot_encode(y_val), Z_test),\n",
    "                             'HTS': hts.predictive(Z_test),\n",
    "                             'HTS_torch': hts_t.predictive(Z_test),\n",
    "                             'LTS': lts.predictive(Z_test),\n",
    "                             'LTS_torch': lts_t.predictive(Z_test),\n",
    "                             'HnLTS': hlts.predictive(Z_test),\n",
    "                             'HnLTS_torch': hlts_t.predictive(Z_test)}, target=y_test, M=50, from_logits=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4597e55",
   "metadata": {},
   "source": [
    "### Temperature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893df8e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54bfb3641487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlhaTempScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(25, 25))\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_train)\n",
    "ax[0, 0].hist(Ts, bins=50)\n",
    "ax[0, 0].set_xlabel('T', fontsize=22)\n",
    "ax[0, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_val)\n",
    "ax[0, 1].hist(Ts, bins=50)\n",
    "ax[0, 1].set_xlabel('T', fontsize=22)\n",
    "ax[0, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = lhaTempScaler.get_T(Z_test)\n",
    "ax[0, 2].hist(Ts, bins=50)\n",
    "ax[0, 2].set_xlabel('T', fontsize=22)\n",
    "ax[0, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[0, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_train)\n",
    "ax[1, 0].hist(Ts, bins=50)\n",
    "ax[1, 0].set_xlabel('T', fontsize=22)\n",
    "ax[1, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_val)\n",
    "ax[1, 1].hist(Ts, bins=50)\n",
    "ax[1, 1].set_xlabel('T', fontsize=22)\n",
    "ax[1, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = dnnaTempScaler.get_T(Z_test)\n",
    "ax[1, 2].hist(Ts, bins=50)\n",
    "ax[1, 2].set_xlabel('T', fontsize=22)\n",
    "ax[1, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[1, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_train)\n",
    "ax[2, 0].hist(Ts, bins=50)\n",
    "ax[2, 0].set_xlabel('T', fontsize=22)\n",
    "ax[2, 0].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 0].set_title('Train set', fontsize=26)\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_val)\n",
    "ax[2, 1].hist(Ts, bins=50)\n",
    "ax[2, 1].set_xlabel('T', fontsize=22)\n",
    "ax[2, 1].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 1].set_title('Validation set', fontsize=26)\n",
    "\n",
    "Ts = bdnnaTempScaler.get_T(Z_test)\n",
    "ax[2, 2].hist(Ts, bins=50)\n",
    "ax[2, 2].set_xlabel('T', fontsize=22)\n",
    "ax[2, 2].set_ylabel('Count', fontsize=22)\n",
    "ax[2, 2].set_title('Test set', fontsize=26)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ec4f8",
   "metadata": {},
   "source": [
    "### Selected temperature for different confidences in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc, lc, hi, li = calib_split(Z_test, y_test)\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[hc | hi], y_test[hc | hi]);\n",
    "T_hc = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[lc | li], y_test[lc | li]);\n",
    "T_lc = ts_aux.T.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09623351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TslH = lhaTempScaler.get_T(Z_test)\n",
    "TsDNN = dnnaTempScaler.get_T(Z_test)\n",
    "TsBDNN = bdnnaTempScaler.get_T(Z_test)\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(23, 25))\n",
    "\n",
    "\n",
    "ax[0, 0].hist(TslH[hc | hi])\n",
    "ax[0, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[0, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[hc | hi])), fontsize=26)\n",
    "ax[0, 0].legend(fontsize=18)\n",
    "\n",
    "ax[0, 1].hist(TslH[lc | li])\n",
    "ax[0, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[0, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[lc | li])), fontsize=26)\n",
    "ax[0, 1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[1, 0].hist(TsDNN[hc | hi])\n",
    "ax[1, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[1, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[hc | hi])), fontsize=26)\n",
    "ax[1, 0].legend(fontsize=18)\n",
    "\n",
    "ax[1, 1].hist(TsDNN[lc | li])\n",
    "ax[1, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[1, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[lc | li])), fontsize=26)\n",
    "ax[1, 1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[2, 0].hist(TsBDNN[hc | hi])\n",
    "ax[2, 0].axvline(T_hc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_hc[0]))\n",
    "ax[2, 0].set_title('High Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[hc | hi])), fontsize=26)\n",
    "ax[2, 0].legend(fontsize=18)\n",
    "\n",
    "ax[2, 1].hist(TsBDNN[lc | li])\n",
    "ax[2, 1].axvline(T_lc, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_lc[0]))\n",
    "ax[2, 1].set_title('Low Confidence samples.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[lc | li])), fontsize=26)\n",
    "ax[2, 1].legend(fontsize=18)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.yaxis.set_tick_params(labelleft=True)\n",
    "    _ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    _ax.set_xlabel('T', fontsize=22)\n",
    "    _ax.set_ylabel('Count', fontsize=22)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5d208",
   "metadata": {},
   "source": [
    "### According to quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = softmax(Z_test, axis=1)\n",
    "test_confs = np.max(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 8))\n",
    "\n",
    "ax.hist(test_confs, bins=200)\n",
    "\n",
    "ax.set_xlabel('Confidence', fontsize=22)\n",
    "ax.set_ylabel('Count', fontsize=22)\n",
    "ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.argsort(test_confs)\n",
    "\n",
    "q1, q2, q3, q4 = ix[:len(test_confs)//4], ix[len(test_confs)//4:len(test_confs)//2], ix[len(test_confs)//2: 3*len(test_confs)//4], ix[3*len(test_confs)//4:]\n",
    "\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q1], y_test[q1]);\n",
    "T_q1 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q2], y_test[q2]);\n",
    "T_q2 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q3], y_test[q3]);\n",
    "T_q3 = ts_aux.T.detach().numpy()\n",
    "\n",
    "ts_aux = TempScaling()\n",
    "ts_aux.fit(Z_test[q4], y_test[q4]);\n",
    "T_q4 = ts_aux.T.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "TslH = lhaTempScaler.get_T(Z_test)\n",
    "TsDNN = dnnaTempScaler.get_T(Z_test)\n",
    "TsBDNN = bdnnaTempScaler.get_T(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a50e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, sharex=True, sharey=True, figsize=(30, 25))\n",
    "\n",
    "\n",
    "ax[0, 0].hist(TslH[q1])\n",
    "ax[0, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[0, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q1])), fontsize=26)\n",
    "\n",
    "ax[0, 1].hist(TslH[q2])\n",
    "ax[0, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[0, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q2])), fontsize=26)\n",
    "\n",
    "ax[0, 2].hist(TslH[q3])\n",
    "ax[0, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[0, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q3])), fontsize=26)\n",
    "\n",
    "ax[0, 3].hist(TslH[q4])\n",
    "ax[0, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[0, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TslH[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "ax[1, 0].hist(TsDNN[q1])\n",
    "ax[1, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[1, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q1])), fontsize=26)\n",
    "\n",
    "ax[1, 1].hist(TsDNN[q2])\n",
    "ax[1, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[1, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q2])), fontsize=26)\n",
    "\n",
    "ax[1, 2].hist(TsDNN[q3])\n",
    "ax[1, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[1, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q3])), fontsize=26)\n",
    "\n",
    "ax[1, 3].hist(TsDNN[q4])\n",
    "ax[1, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[1, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsDNN[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "ax[2, 0].hist(TsBDNN[q1])\n",
    "ax[2, 0].axvline(T_q1, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q1[0]))\n",
    "ax[2, 0].set_title('Samples in Q1.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q1])), fontsize=26)\n",
    "\n",
    "ax[2, 1].hist(TsBDNN[q2])\n",
    "ax[2, 1].axvline(T_q2, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q2[0]))\n",
    "ax[2, 1].set_title('Samples in Q2.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q2])), fontsize=26)\n",
    "\n",
    "ax[2, 2].hist(TsBDNN[q3])\n",
    "ax[2, 2].axvline(T_q3, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q3[0]))\n",
    "ax[2, 2].set_title('Samples in Q3.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q3])), fontsize=26)\n",
    "\n",
    "ax[2, 3].hist(TsBDNN[q4])\n",
    "ax[2, 3].axvline(T_q4, ls='--', lw=2, c='red', label='Optimum Temperature $T = {:.3f}$'.format(T_q4[0]))\n",
    "ax[2, 3].set_title('Samples in Q4.\\n $\\mathbb{{E}}[T] = {:.3f}$'.format(np.mean(TsBDNN[q4])), fontsize=26)\n",
    "\n",
    "\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.yaxis.set_tick_params(labelleft=True)\n",
    "    _ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.set_xlabel('T', fontsize=22)\n",
    "    _ax.set_ylabel('Count', fontsize=22)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b404121",
   "metadata": {},
   "source": [
    "## Corruption Robustness: CIFAR10-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ef3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c = get_CIFAR10_C(CIFAR10C_PATH)\n",
    "\n",
    "categories = list(cifar10c.keys())\n",
    "categories.remove('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c462c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_transforms_test=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ba994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = load_model('resnet50', 'cifar10', model_path='../../trained_models') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae107dc",
   "metadata": {},
   "source": [
    "### Robustness without exposure to corrupted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3af6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_logits = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_logits[category] = {}\n",
    "    print('Computing predictions for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        test_data = NumpyDataset(cifar10c[category][severity], cifar10c['labels'][:10000], transform=cifar10_transforms_test)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=256)\n",
    "        cifar10c_logits[category][severity] = predict_logits(net, test_dataloader, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_metrics_uncal = {}\n",
    "cifar10c_metrics_tscal = {}\n",
    "cifar10c_metrics_lhtscal = {}\n",
    "cifar10c_metrics_dnntscal = {}\n",
    "cifar10c_metrics_bdnntscal = {}\n",
    "cifar10c_metrics_histtscal = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_metrics_uncal[category] = {}\n",
    "    cifar10c_metrics_tscal[category] = {}\n",
    "    cifar10c_metrics_lhtscal[category] = {}\n",
    "    cifar10c_metrics_dnntscal[category] = {}\n",
    "    cifar10c_metrics_bdnntscal[category] = {}\n",
    "    cifar10c_metrics_histtscal[category] = {}\n",
    "    print('Computing metrics for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_metrics_uncal[category][severity] = compute_metrics(cifar10c_logits[category][severity], cifar10c['labels'][:10000])\n",
    "        cifar10c_metrics_tscal[category][severity] = compute_metrics(tempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_lhtscal[category][severity] = compute_metrics(lhaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_dnntscal[category][severity] = compute_metrics(dnnaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_bdnntscal[category][severity] = compute_metrics(bdnnaTempScaler.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)\n",
    "        cifar10c_metrics_histtscal[category][severity] = compute_metrics(hisTS.predictive(cifar10c_logits[category][severity]), cifar10c['labels'][:10000], from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sev_uncal = np.zeros((5, 4))\n",
    "mean_sev_tscal = np.zeros((5, 4))\n",
    "mean_sev_lhtscal = np.zeros((5, 4))\n",
    "mean_sev_dnntscal = np.zeros((5, 4))\n",
    "mean_sev_bdnntscal = np.zeros((5, 4))\n",
    "mean_sev_histtscal = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_sev_uncal[i] += cifar10c_metrics_uncal[cat][i+1]\n",
    "        mean_sev_tscal[i] += cifar10c_metrics_tscal[cat][i+1]\n",
    "        mean_sev_lhtscal[i] += cifar10c_metrics_lhtscal[cat][i+1]\n",
    "        mean_sev_dnntscal[i] += cifar10c_metrics_dnntscal[cat][i+1]\n",
    "        mean_sev_bdnntscal[i] += cifar10c_metrics_bdnntscal[cat][i+1]\n",
    "        mean_sev_histtscal[i] += cifar10c_metrics_histtscal[cat][i+1]\n",
    "        \n",
    "mean_sev_uncal /= len(categories)\n",
    "mean_sev_tscal /= len(categories)\n",
    "mean_sev_lhtscal /= len(categories)\n",
    "mean_sev_dnntscal /= len(categories)\n",
    "mean_sev_bdnntscal /= len(categories)\n",
    "mean_sev_histtscal /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd128354",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(28, 33))\n",
    "\n",
    "# ax[0].plot(mean_sev_uncal[:, 1], ls='--', marker='*', label='Uncalibrated')\n",
    "ax[0].plot(mean_sev_tscal[:, 1], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[0].plot(mean_sev_lhtscal[:, 1], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[0].plot(mean_sev_dnntscal[:, 1], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_bdnntscal[:, 1], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_histtscal[:, 1], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[0].set_ylabel('ECE', fontsize=22)\n",
    "\n",
    "# ax[1].plot(mnll_sev_uncal, label='Uncalibrated')\n",
    "ax[1].plot(mean_sev_tscal[:, 3], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[1].plot(mean_sev_lhtscal[:, 3], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[1].plot(mean_sev_dnntscal[:, 3], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_bdnntscal[:, 3], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_histtscal[:, 3], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[1].set_ylabel('NLL', fontsize=22)\n",
    "\n",
    "ax[2].plot(mean_sev_tscal[:, 2], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[2].plot(mean_sev_lhtscal[:, 2], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[2].plot(mean_sev_dnntscal[:, 2], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_bdnntscal[:, 2], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_histtscal[:, 2], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[2].set_ylabel('Brier Score', fontsize=22)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.set_xticks(np.arange(5))\n",
    "    _ax.set_xticklabels(np.arange(5) + 1)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    _ax.set_xlabel('Corruption level', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019896df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_TslH= {}\n",
    "cifar10c_TsDNN= {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_TslH[category] = {}\n",
    "    cifar10c_TsDNN[category] = {}\n",
    "    print('Computing Ts for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_TslH[category][severity] = lhaTempScaler.get_T(cifar10c_logits[category][severity])\n",
    "        cifar10c_TsDNN[category][severity] = dnnaTempScaler.get_T(cifar10c_logits[category][severity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d626ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_TslH = np.zeros(5)\n",
    "mean_TsDNN = np.zeros(5)\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_TslH[i] += np.mean(cifar10c_TslH[cat][i+1])\n",
    "        mean_TsDNN[i] += np.mean(cifar10c_TsDNN[cat][i+1])\n",
    "        \n",
    "mean_TslH /= len(categories)\n",
    "mean_TsDNN /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_TslH)\n",
    "print(mean_TsDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a0d061",
   "metadata": {},
   "source": [
    "### Exposure to corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = np.random.permutation(10000)\n",
    "idx_train = rnd_idx[:3000]\n",
    "idx_test = rnd_idx[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.vstack([cifar10c_logits[cat][i+1][idx_train] for cat in categories for i in range(5)])\n",
    "y_train = np.hstack([cifar10c['labels'][idx_train] for cat in categories for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bea6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temp-Scal as baseline:\n",
    "tempScaler = TempScaling()\n",
    "tempScaler.fit(train_set, y_train, v=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhaTempScaler = AdaTS(HlogbasedT(dim))\n",
    "lhaTempScaler = fitAdaTS(lhaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnaTempScaler = AdaTS(DNNbasedT(dim))\n",
    "dnnaTempScaler = fitAdaTS(dnnaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdnnaTempScaler = AdaTS(DNNbasedT(dim, hs=[2*dim, 2*dim]))\n",
    "bdnnaTempScaler = fitAdaTS(bdnnaTempScaler, train_set, y_train, epochs=10000, batch_size=1000, lr=1e-4, v=True, weight_decay=1e-2, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a04b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hisTS = HistTS()\n",
    "hisTS.fit(train_set, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366945ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10c_metrics_uncal = {}\n",
    "cifar10c_metrics_tscal = {}\n",
    "cifar10c_metrics_lhtscal = {}\n",
    "cifar10c_metrics_dnntscal = {}\n",
    "cifar10c_metrics_bdnntscal = {}\n",
    "cifar10c_metrics_histtscal = {}\n",
    "\n",
    "for category in categories:\n",
    "    cifar10c_metrics_uncal[category] = {}\n",
    "    cifar10c_metrics_tscal[category] = {}\n",
    "    cifar10c_metrics_lhtscal[category] = {}\n",
    "    cifar10c_metrics_dnntscal[category] = {}\n",
    "    cifar10c_metrics_bdnntscal[category] = {}\n",
    "    cifar10c_metrics_histtscal[category] = {}\n",
    "    print('Computing metrics for corruption: {}'.format(category))\n",
    "    for severity in range(1, 6):\n",
    "        cifar10c_metrics_uncal[category][severity] = compute_metrics(cifar10c_logits[category][severity][idx_test], cifar10c['labels'][idx_test])\n",
    "        cifar10c_metrics_tscal[category][severity] = compute_metrics(tempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_lhtscal[category][severity] = compute_metrics(lhaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_dnntscal[category][severity] = compute_metrics(dnnaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_bdnntscal[category][severity] = compute_metrics(bdnnaTempScaler.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)\n",
    "        cifar10c_metrics_histtscal[category][severity] = compute_metrics(hisTS.predictive(cifar10c_logits[category][severity][idx_test]), cifar10c['labels'][idx_test], from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2440ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sev_uncal = np.zeros((5, 4))\n",
    "mean_sev_tscal = np.zeros((5, 4))\n",
    "mean_sev_lhtscal = np.zeros((5, 4))\n",
    "mean_sev_dnntscal = np.zeros((5, 4))\n",
    "mean_sev_bdnntscal = np.zeros((5, 4))\n",
    "mean_sev_histtscal = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for cat in categories:\n",
    "        mean_sev_uncal[i] += cifar10c_metrics_uncal[cat][i+1]\n",
    "        mean_sev_tscal[i] += cifar10c_metrics_tscal[cat][i+1]\n",
    "        mean_sev_lhtscal[i] += cifar10c_metrics_lhtscal[cat][i+1]\n",
    "        mean_sev_dnntscal[i] += cifar10c_metrics_dnntscal[cat][i+1]\n",
    "        mean_sev_bdnntscal[i] += cifar10c_metrics_bdnntscal[cat][i+1]\n",
    "        mean_sev_histtscal[i] += cifar10c_metrics_histtscal[cat][i+1]\n",
    "        \n",
    "mean_sev_uncal /= len(categories)\n",
    "mean_sev_tscal /= len(categories)\n",
    "mean_sev_lhtscal /= len(categories)\n",
    "mean_sev_dnntscal /= len(categories)\n",
    "mean_sev_bdnntscal /= len(categories)\n",
    "mean_sev_histtscal /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d512574",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(28, 33))\n",
    "\n",
    "# ax[0].plot(mean_sev_uncal[:, 1], ls='--', marker='*', label='Uncalibrated')\n",
    "ax[0].plot(mean_sev_tscal[:, 1], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[0].plot(mean_sev_lhtscal[:, 1], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[0].plot(mean_sev_dnntscal[:, 1], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_bdnntscal[:, 1], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[0].plot(mean_sev_histtscal[:, 1], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[0].set_ylabel('ECE', fontsize=22)\n",
    "\n",
    "# ax[1].plot(mnll_sev_uncal, label='Uncalibrated')\n",
    "ax[1].plot(mean_sev_tscal[:, 3], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[1].plot(mean_sev_lhtscal[:, 3], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[1].plot(mean_sev_dnntscal[:, 3], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_bdnntscal[:, 3], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[1].plot(mean_sev_histtscal[:, 3], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[1].set_ylabel('NLL', fontsize=22)\n",
    "\n",
    "ax[2].plot(mean_sev_tscal[:, 2], ls='--', marker='*', label='Temp-Scaling')\n",
    "ax[2].plot(mean_sev_lhtscal[:, 2], ls='--', marker='*', label='$\\log H$ Temp-Scaling')\n",
    "ax[2].plot(mean_sev_dnntscal[:, 2], ls='--', marker='*', label='DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_bdnntscal[:, 2], ls='--', marker='*', label='Big DNN Temp-Scaling')\n",
    "ax[2].plot(mean_sev_histtscal[:, 2], ls='--', marker='*', label='H Hist Temp-Scaling')\n",
    "ax[2].set_ylabel('Brier Score', fontsize=22)\n",
    "\n",
    "for _ax in ax.flatten():\n",
    "    _ax.set_xticks(np.arange(5))\n",
    "    _ax.set_xticklabels(np.arange(5) + 1)\n",
    "    _ax.legend(fontsize=18)\n",
    "    _ax.tick_params(axis='both', labelsize=18)\n",
    "    _ax.set_xlabel('Corruption level', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb50b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
